{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, multilabel_confusion_matrix, \\\n",
    "    plot_confusion_matrix,classification_report, confusion_matrix, precision_score, \\\n",
    "    recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment when using in Google Colab\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment when using in Google Colab\n",
    "# import io\n",
    "# mass = pd.read_csv(io.BytesIO(uploaded['mass_mobile.csv']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load cleaned data from a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass = pd.read_csv('../data/03_mass_no_country.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>country</th>\n",
       "      <th>ccode</th>\n",
       "      <th>region</th>\n",
       "      <th>protestnumber</th>\n",
       "      <th>protesterviolence</th>\n",
       "      <th>location</th>\n",
       "      <th>protesteridentity</th>\n",
       "      <th>sources</th>\n",
       "      <th>notes</th>\n",
       "      <th>...</th>\n",
       "      <th>end_date</th>\n",
       "      <th>target</th>\n",
       "      <th>notes_clean</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>protest_duration</th>\n",
       "      <th>violent_response</th>\n",
       "      <th>violent_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201990001</td>\n",
       "      <td>Canada</td>\n",
       "      <td>20</td>\n",
       "      <td>North America</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>national</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>1. great canadian train journeys into history;...</td>\n",
       "      <td>canada s railway passenger system was finally ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1990-01-15</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>canada s railway passenger system was finally ...</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.8176</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201990002</td>\n",
       "      <td>Canada</td>\n",
       "      <td>20</td>\n",
       "      <td>North America</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Montreal, Quebec</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>1. autonomy s cry revived in quebec the new yo...</td>\n",
       "      <td>protestors were only identified as young peopl...</td>\n",
       "      <td>...</td>\n",
       "      <td>1990-06-25</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>protestors were only identified as young peopl...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201990003</td>\n",
       "      <td>Canada</td>\n",
       "      <td>20</td>\n",
       "      <td>North America</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Montreal, Quebec</td>\n",
       "      <td>separatist parti quebecois</td>\n",
       "      <td>1. quebec protest after queen calls for unity ...</td>\n",
       "      <td>the queen, after calling on canadians to remai...</td>\n",
       "      <td>...</td>\n",
       "      <td>1990-07-01</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>the queen, after calling on canadians to remai...</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.7003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id country  ccode         region  protestnumber  protesterviolence  \\\n",
       "0  201990001  Canada     20  North America              1                0.0   \n",
       "1  201990002  Canada     20  North America              2                0.0   \n",
       "2  201990003  Canada     20  North America              3                0.0   \n",
       "\n",
       "           location           protesteridentity  \\\n",
       "0          national                 unspecified   \n",
       "1  Montreal, Quebec                 unspecified   \n",
       "2  Montreal, Quebec  separatist parti quebecois   \n",
       "\n",
       "                                             sources  \\\n",
       "0  1. great canadian train journeys into history;...   \n",
       "1  1. autonomy s cry revived in quebec the new yo...   \n",
       "2  1. quebec protest after queen calls for unity ...   \n",
       "\n",
       "                                               notes  ...    end_date  \\\n",
       "0  canada s railway passenger system was finally ...  ...  1990-01-15   \n",
       "1  protestors were only identified as young peopl...  ...  1990-06-25   \n",
       "2  the queen, after calling on canadians to remai...  ...  1990-07-01   \n",
       "\n",
       "                  target                                        notes_clean  \\\n",
       "0  [0, 0, 0, 0, 1, 0, 0]  canada s railway passenger system was finally ...   \n",
       "1  [0, 0, 0, 0, 1, 0, 0]  protestors were only identified as young peopl...   \n",
       "2  [0, 0, 0, 0, 1, 0, 0]  the queen, after calling on canadians to remai...   \n",
       "\n",
       "     neg    neu    pos  compound  protest_duration  violent_response  \\\n",
       "0  0.087  0.913  0.000   -0.8176                 1                 0   \n",
       "1  0.000  1.000  0.000    0.0000                 1                 0   \n",
       "2  0.060  0.830  0.109    0.7003                 1                 0   \n",
       "\n",
       "   violent_count  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "\n",
       "[3 rows x 71 columns]"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X will be set to use 40 features.\n"
     ]
    }
   ],
   "source": [
    "# User dataframe of almost all features.\n",
    "\n",
    "features = mass.drop(columns=['id', 'country', 'ccode', 'region', 'location','protesteridentity', 'sources',\n",
    "           'notes', 'protester_id_type', 'protest_size_category', 'start_date', 'notes_clean', 'neg', 'neu', 'pos', 'compound',\n",
    "           'end_date', 'target', 'arrests', 'accomodation', 'beatings', 'crowddispersal', 'ignore', 'killings', 'shootings', \n",
    "           'partipants_number','pop_male', 'pop_female', 'violent_response', 'violent_count', 'protest_duration'])\n",
    "\n",
    "\n",
    "print(f'X will be set to use {features.shape[1]} features.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country_list - this code applies to when using a different csv file that DID included a dummied column for each country\n",
    "#country_column_names = list(features_1.columns[9:174])\n",
    "#features = features_1.drop(country_column_names, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# This code was initially used to define a small set of features just to get a small model going.\n",
    "# features = ['pop_density', 'prosperity_2020','partipants_number','compound','region_Europe','region_Central America','region_Africa',\n",
    "# 'region_MENA', 'region_North America', 'region_Oceania', 'region_South America']\n",
    "#X = mass[features]\n",
    "\n",
    "X = features\n",
    "y = np.array(mass[['arrests', 'accomodation', 'beatings',\n",
    "       'crowddispersal', 'ignore', 'killings', 'shootings']])\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15179"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To use a Gridsearch with the MultiOutputClassifer, uncomment the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up MultiOutputClassifier\n",
    "#model_grad_booster = MultiOutputClassifier(GradientBoostingClassifier())\n",
    "\n",
    "# Set up hyperparameters\n",
    "# hyperparameters_grad = dict(estimator__learning_rate=[ 0.2, 0.5], \n",
    "#                      estimator__n_estimators=[20, 50, 100],\n",
    "#                      estimator__min_samples_split=[2, 4, 7, 10],\n",
    "#                      estimator__max_depth=[5, 20, 30], \n",
    "#                      estimator__min_samples_leaf=[ 5, 8, 10],\n",
    "#                      estimator__min_impurity_decrease=[0.2, 0.6, 0.8],\n",
    "#                      estimator__max_leaf_nodes=[5, 20, 100])\n",
    "\n",
    "# Execute Grid Search\n",
    "# grid_search = GridSearchCV(model_grad_booster, hyperparameters_grad,n_jobs=-1, cv=5, verbose=True,\n",
    "#                                        pre_dispatch='2*n_jobs', error_score='raise', return_train_score=True)\n",
    "\n",
    "# Fit the model\n",
    "#hyperparameters_tuning = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Current model uses a Randomized CV Search, MultiOutputClassifier of a Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MultiOutputClassifier' object has no attribute 'estimators_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-514-6a3ed4768cbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mhyperparameters_tuning\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandomized_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34mf'How many estimators: {len(model_random_forest.estimators_)} '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregr_multi_RF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MultiOutputClassifier' object has no attribute 'estimators_'"
     ]
    }
   ],
   "source": [
    "\n",
    "# set up MultiOutputClassifier\n",
    "model_random_forest = MultiOutputClassifier(RandomForestClassifier())  \n",
    "\n",
    "# Set up hyperparameters\n",
    "hyperparameters_forest = dict(estimator__n_estimators=[20, 50, 100, 200, 300, 500, 1000],\n",
    "                       estimator__min_samples_split=[2, 4, 7, 10],\n",
    "                       estimator__max_depth=[3, 5, 10, 15, 20, 30],\n",
    "                       estimator__min_samples_leaf=[1, 2, 3, 5, 8, 10],\n",
    "                       estimator__min_impurity_decrease=[0, 0.2, 0.4, 0.6, 0.8],\n",
    "                       estimator__max_leaf_nodes=[5, 10, 20, 30, 50, 100, 300])\n",
    "\n",
    "# n_iter   int, default=10 - might want to increase?\n",
    "\n",
    "# Set up Random Search criteria\n",
    "randomized_search = RandomizedSearchCV(model_random_forest, hyperparameters_forest,\n",
    "                                       n_jobs=-1, cv=5, verbose=1, n_iter=30,\n",
    "                                       error_score='raise')\n",
    "\n",
    "# Fit the model\n",
    "hyperparameters_tuning = randomized_search.fit(X_train, y_train)\n",
    "\n",
    "len(regr_multi_RF.estimators_)\n",
    "\n",
    "print('Best Parameters = {}'.format(hyperparameters_tuning.best_params_))\n",
    "\n",
    "# Set model variable to be the best performing estimator\n",
    "tuned_model = hyperparameters_tuning.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print best score\n",
    "If no scoring method is assigned to the `RandomizedSearchCV` function, the it uses the scoring method associated with the model, which in this case is `RandomForestClassifier`.  \n",
    "\n",
    "RandomForestClassifier's scoring function:\n",
    "> Return the mean accuracy on the given test data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_tuning.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get predictions using `X_test` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = tuned_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model.score(X_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save four rows of features so we can run a test of using the model after loading its pickle file in another notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.iloc[0:4].to_csv('../data/x_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export tuned model to use for predictions in another notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "model_file_name = '../models/01_multi_label_forest.pickle'\n",
    "pickle.dump(  tuned_model     , open(   model_file_name, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hat tip to this blog post:\n",
    "# https://medium.com/@saugata.paul1010/a-detailed-case-study-on-multi-label-classification-with-machine-learning-algorithms-and-72031742c9aa\n",
    "\n",
    "print(\"Accuracy = \", accuracy_score(y_test,y_preds))\n",
    "\n",
    "precision = precision_score(y_test, y_preds, average='micro')\n",
    "recall = recall_score(y_test, y_preds, average='micro')\n",
    "f1 = f1_score(y_test, y_preds, average='micro')\n",
    " \n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame(data=y, columns=['arrests', 'accomodation', 'beatings',\n",
    "       'crowddispersal', 'ignore', 'killings', 'shootings'])\n",
    "y_df[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of all 1's in all columns, divided by the number of rows in the train dataset\n",
    "pd.DataFrame(y_df.sum() / y_df.shape[0]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df.sum(axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print confusion matrix for all target variables (state responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multilabel_confusion_matrix function returns an array of seven confusion matrices (on for each target variable).\n",
    "\n",
    "Each Seaborn heatmap loads one of the matrices from the array (called `cm_array`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_array = multilabel_confusion_matrix(y_test, y_preds)  # this returns an array of confusion matrices\n",
    "cm_array[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For better readability, just plot two at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,4))\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "\n",
    "sns.heatmap(cm_array[0].astype(int), annot=True, ax = ax1, cmap='Greens', fmt='d'); #annot=True to annotate cells\n",
    "\n",
    "# labels, title and ticks\n",
    "ax1.set_xlabel('Predicted State Response');\n",
    "ax1.set_ylabel('Actual State Response'); \n",
    "ax1.set_title('Confusion Matrix'); \n",
    "ax1.xaxis.set_ticklabels(['No Arrests', 'Arrests']);\n",
    "ax1.yaxis.set_ticklabels(['No Arrests', 'Arrests'], va='center');\n",
    "\n",
    "sns.heatmap(cm_array[1].astype(int), annot=True, ax = ax2, cmap='Greens', fmt='d'); #annot=True to annotate cells\n",
    "\n",
    "# labels, title and ticks\n",
    "ax2.set_xlabel('Predicted State Response');\n",
    "ax2.set_ylabel('Actual State Response'); \n",
    "ax2.set_title('Confusion Matrix'); \n",
    "ax2.xaxis.set_ticklabels(['No Accomodation', 'Accomodation']);\n",
    "ax2.yaxis.set_ticklabels(['No Accomodation', 'Accomodation'], va='center');\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,4))\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "\n",
    "sns.heatmap(cm_array[2].astype(int), annot=True, ax = ax1, cmap='crest', fmt='d'); #annot=True to annotate cells\n",
    "\n",
    "# labels, title and ticks\n",
    "ax1.set_xlabel('Predicted State Response');\n",
    "ax1.set_ylabel('Actual State Response'); \n",
    "ax1.set_title('Confusion Matrix'); \n",
    "ax1.xaxis.set_ticklabels(['No Beatings', 'Beatings']);\n",
    "ax1.yaxis.set_ticklabels(['No Beatings', 'Beatings'], va='center');\n",
    "\n",
    "sns.heatmap(cm_array[3].astype(int), annot=True, ax = ax2, cmap='Greens', fmt='d'); #annot=True to annotate cells\n",
    "\n",
    "# labels, title and ticks\n",
    "ax2.set_xlabel('Predicted State Response');\n",
    "ax2.set_ylabel('Actual State Response'); \n",
    "ax2.set_title('Confusion Matrix'); \n",
    "ax2.xaxis.set_ticklabels(['No Crowd Dispersal', 'Crowd Dispersal']);\n",
    "ax2.yaxis.set_ticklabels(['No Crowd Dispersal', 'Crowd Dispersal'], va='center');\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,4))\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "\n",
    "sns.heatmap(cm_array[5].astype(int), annot=True, ax = ax1, cmap='Reds', fmt='d'); #annot=True to annotate cells\n",
    "\n",
    "# labels, title and ticks\n",
    "ax1.set_xlabel('Predicted State Response');\n",
    "ax1.set_ylabel('Actual State Response'); \n",
    "ax1.set_title('Confusion Matrix'); \n",
    "ax1.xaxis.set_ticklabels(['No Killings', 'Killings']);\n",
    "ax1.yaxis.set_ticklabels(['No Killings', 'Killings'], va='center');\n",
    "\n",
    "sns.heatmap(cm_array[6].astype(int), annot=True, ax = ax2, cmap='Reds', fmt='d'); #annot=True to annotate cells\n",
    "\n",
    "# labels, title and ticks\n",
    "ax2.set_xlabel('Predicted State Response');\n",
    "ax2.set_ylabel('Actual State Response'); \n",
    "ax2.set_title('Confusion Matrix'); \n",
    "ax2.xaxis.set_ticklabels(['No Shootings', 'Shootings']);\n",
    "ax2.yaxis.set_ticklabels(['No Shootings', 'Shootings'], va='center');\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize=(6,4))\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "\n",
    "sns.heatmap(cm_array[4].astype(int), annot=True, ax = ax1, cmap='Blues', fmt='d'); #annot=True to annotate cells\n",
    "\n",
    "# labels, title and ticks\n",
    "ax1.set_xlabel('Predicted State Response');\n",
    "ax1.set_ylabel('Actual State Response'); \n",
    "ax1.set_title('Confusion Matrix'); \n",
    "ax1.xaxis.set_ticklabels(['No Ignore', 'Ignore']);\n",
    "ax1.yaxis.set_ticklabels(['No Ignore', 'Ignore'], va='center');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( classification_report(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get predictions from all rows in X?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_modeled = tuned_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_modeled[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare to model using ClassifierChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)\n",
    "\n",
    "# using classifier chains\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# initialize classifier chains multi-label classifier\n",
    "classifier = ClassifierChain(LogisticRegression())\n",
    "# Training logistic regression model on train data\n",
    "classifier.fit(X_train_sc, y_train)\n",
    "# predict\n",
    "predictions = classifier.predict(X_test_sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "print(\"Accuracy = \", accuracy_score(y_test,predictions))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
