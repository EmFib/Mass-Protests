{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, LeaveOneOut, cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                            confusion_matrix, \n",
    "                            classification_report,\n",
    "                            f1_score,\n",
    "                            plot_confusion_matrix,\n",
    "                            precision_recall_curve,\n",
    "                            precision_score,\n",
    "                            recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/emilynaftalin/Data_Science/General Assembly/dsi/projects/Mass-Protests/users'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass = pd.read_csv('../data/mass_mobile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>country</th>\n",
       "      <th>ccode</th>\n",
       "      <th>region</th>\n",
       "      <th>protestnumber</th>\n",
       "      <th>protesterviolence</th>\n",
       "      <th>location</th>\n",
       "      <th>protesteridentity</th>\n",
       "      <th>sources</th>\n",
       "      <th>notes</th>\n",
       "      <th>...</th>\n",
       "      <th>social_restrictions</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>target</th>\n",
       "      <th>notes_clean</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>protest_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201990001</td>\n",
       "      <td>Canada</td>\n",
       "      <td>20</td>\n",
       "      <td>North America</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>national</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>1. great canadian train journeys into history;...</td>\n",
       "      <td>canada s railway passenger system was finally ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1990-01-15</td>\n",
       "      <td>1990-01-15</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>canada s railway passenger system was finally ...</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.8176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201990002</td>\n",
       "      <td>Canada</td>\n",
       "      <td>20</td>\n",
       "      <td>North America</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Montreal, Quebec</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>1. autonomy s cry revived in quebec the new yo...</td>\n",
       "      <td>protestors were only identified as young peopl...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1990-06-25</td>\n",
       "      <td>1990-06-25</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>protestors were only identified as young peopl...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id country  ccode         region  protestnumber  protesterviolence  \\\n",
       "0  201990001  Canada     20  North America              1                0.0   \n",
       "1  201990002  Canada     20  North America              2                0.0   \n",
       "\n",
       "           location protesteridentity  \\\n",
       "0          national       unspecified   \n",
       "1  Montreal, Quebec       unspecified   \n",
       "\n",
       "                                             sources  \\\n",
       "0  1. great canadian train journeys into history;...   \n",
       "1  1. autonomy s cry revived in quebec the new yo...   \n",
       "\n",
       "                                               notes  ... social_restrictions  \\\n",
       "0  canada s railway passenger system was finally ...  ...                   0   \n",
       "1  protestors were only identified as young peopl...  ...                   0   \n",
       "\n",
       "   start_date    end_date                 target  \\\n",
       "0  1990-01-15  1990-01-15  [0, 0, 0, 0, 1, 0, 0]   \n",
       "1  1990-06-25  1990-06-25  [0, 0, 0, 0, 1, 0, 0]   \n",
       "\n",
       "                                         notes_clean    neg    neu  pos  \\\n",
       "0  canada s railway passenger system was finally ...  0.087  0.913  0.0   \n",
       "1  protestors were only identified as young peopl...  0.000  1.000  0.0   \n",
       "\n",
       "   compound  protest_duration  \n",
       "0   -0.8176                 1  \n",
       "1    0.0000                 1  \n",
       "\n",
       "[2 rows x 234 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accomodation',\n",
       " 'arrests',\n",
       " 'beatings',\n",
       " 'ccode',\n",
       " 'compound',\n",
       " 'country',\n",
       " 'country_Afghanistan',\n",
       " 'country_Albania',\n",
       " 'country_Algeria',\n",
       " 'country_Angola',\n",
       " 'country_Argentina',\n",
       " 'country_Armenia',\n",
       " 'country_Austria',\n",
       " 'country_Azerbaijan',\n",
       " 'country_Bahrain',\n",
       " 'country_Bangladesh',\n",
       " 'country_Belarus',\n",
       " 'country_Belgium',\n",
       " 'country_Benin',\n",
       " 'country_Bolivia',\n",
       " 'country_Bosnia',\n",
       " 'country_Botswana',\n",
       " 'country_Brazil',\n",
       " 'country_Bulgaria',\n",
       " 'country_Burkina Faso',\n",
       " 'country_Burundi',\n",
       " 'country_Cambodia',\n",
       " 'country_Cameroon',\n",
       " 'country_Canada',\n",
       " 'country_Cape Verde',\n",
       " 'country_Central African Republic',\n",
       " 'country_Chad',\n",
       " 'country_Chile',\n",
       " 'country_China',\n",
       " 'country_Colombia',\n",
       " 'country_Comoros',\n",
       " 'country_Congo Brazzaville',\n",
       " 'country_Congo Kinshasa',\n",
       " 'country_Costa Rica',\n",
       " 'country_Croatia',\n",
       " 'country_Cuba',\n",
       " 'country_Cyprus',\n",
       " 'country_Czech Republic',\n",
       " 'country_Czechoslovakia',\n",
       " 'country_Denmark',\n",
       " 'country_Djibouti',\n",
       " 'country_Dominican Republic',\n",
       " 'country_Ecuador',\n",
       " 'country_Egypt',\n",
       " 'country_El Salvador',\n",
       " 'country_Equatorial Guinea',\n",
       " 'country_Eritrea',\n",
       " 'country_Estonia',\n",
       " 'country_Ethiopia',\n",
       " 'country_Finland',\n",
       " 'country_France',\n",
       " 'country_Gabon',\n",
       " 'country_Gambia',\n",
       " 'country_Georgia',\n",
       " 'country_Germany',\n",
       " 'country_Germany East',\n",
       " 'country_Germany West',\n",
       " 'country_Ghana',\n",
       " 'country_Greece',\n",
       " 'country_Guatemala',\n",
       " 'country_Guinea',\n",
       " 'country_Guinea-Bissau',\n",
       " 'country_Guyana',\n",
       " 'country_Haiti',\n",
       " 'country_Honduras',\n",
       " 'country_Hungary',\n",
       " 'country_India',\n",
       " 'country_Indonesia',\n",
       " 'country_Iran',\n",
       " 'country_Iraq',\n",
       " 'country_Ireland',\n",
       " 'country_Italy',\n",
       " 'country_Ivory Coast',\n",
       " 'country_Jamaica',\n",
       " 'country_Japan',\n",
       " 'country_Jordan',\n",
       " 'country_Kazakhstan',\n",
       " 'country_Kenya',\n",
       " 'country_Kosovo',\n",
       " 'country_Kuwait',\n",
       " 'country_Kyrgyzstan',\n",
       " 'country_Laos',\n",
       " 'country_Latvia',\n",
       " 'country_Lebanon',\n",
       " 'country_Lesotho',\n",
       " 'country_Liberia',\n",
       " 'country_Libya',\n",
       " 'country_Lithuania',\n",
       " 'country_Luxembourg',\n",
       " 'country_Macedonia',\n",
       " 'country_Madagascar',\n",
       " 'country_Malawi',\n",
       " 'country_Malaysia',\n",
       " 'country_Mali',\n",
       " 'country_Mauritania',\n",
       " 'country_Mauritius',\n",
       " 'country_Mexico',\n",
       " 'country_Moldova',\n",
       " 'country_Mongolia',\n",
       " 'country_Montenegro',\n",
       " 'country_Morocco',\n",
       " 'country_Mozambique',\n",
       " 'country_Myanmar',\n",
       " 'country_Namibia',\n",
       " 'country_Nepal',\n",
       " 'country_Netherlands',\n",
       " 'country_Nicaragua',\n",
       " 'country_Niger',\n",
       " 'country_Nigeria',\n",
       " 'country_North Korea',\n",
       " 'country_Norway',\n",
       " 'country_Oman',\n",
       " 'country_Pakistan',\n",
       " 'country_Panama',\n",
       " 'country_Papua New Guinea',\n",
       " 'country_Paraguay',\n",
       " 'country_Peru',\n",
       " 'country_Philippines',\n",
       " 'country_Poland',\n",
       " 'country_Portugal',\n",
       " 'country_Qatar',\n",
       " 'country_Romania',\n",
       " 'country_Russia',\n",
       " 'country_Rwanda',\n",
       " 'country_Saudi Arabia',\n",
       " 'country_Senegal',\n",
       " 'country_Serbia',\n",
       " 'country_Serbia and Montenegro',\n",
       " 'country_Sierra Leone',\n",
       " 'country_Singapore',\n",
       " 'country_Slovak Republic',\n",
       " 'country_Slovenia',\n",
       " 'country_Somalia',\n",
       " 'country_South Africa',\n",
       " 'country_South Korea',\n",
       " 'country_South Sudan',\n",
       " 'country_Spain',\n",
       " 'country_Sri Lanka',\n",
       " 'country_Sudan',\n",
       " 'country_Suriname',\n",
       " 'country_Swaziland',\n",
       " 'country_Sweden',\n",
       " 'country_Switzerland',\n",
       " 'country_Syria',\n",
       " 'country_Taiwan',\n",
       " 'country_Tajikistan',\n",
       " 'country_Tanzania',\n",
       " 'country_Thailand',\n",
       " 'country_Timor Leste',\n",
       " 'country_Togo',\n",
       " 'country_Tunisia',\n",
       " 'country_Turkey',\n",
       " 'country_Turkmenistan',\n",
       " 'country_USSR',\n",
       " 'country_Uganda',\n",
       " 'country_Ukraine',\n",
       " 'country_United Arab Emirate',\n",
       " 'country_United Kingdom',\n",
       " 'country_Uruguay',\n",
       " 'country_Uzbekistan',\n",
       " 'country_Venezuela',\n",
       " 'country_Vietnam',\n",
       " 'country_Yemen',\n",
       " 'country_Yugoslavia',\n",
       " 'country_Zambia',\n",
       " 'country_Zimbabwe',\n",
       " 'crowddispersal',\n",
       " 'end_date',\n",
       " 'id',\n",
       " 'ignore',\n",
       " 'killings',\n",
       " 'labor_wage_dispute',\n",
       " 'land_farm_issue',\n",
       " 'location',\n",
       " 'neg',\n",
       " 'neu',\n",
       " 'notes',\n",
       " 'notes_clean',\n",
       " 'partipants_number',\n",
       " 'police_brutality',\n",
       " 'political_behavior_process',\n",
       " 'pop_density',\n",
       " 'pop_female',\n",
       " 'pop_male',\n",
       " 'pop_total',\n",
       " 'pos',\n",
       " 'price increases_tax_policy',\n",
       " 'prosperity_2020',\n",
       " 'protest_duration',\n",
       " 'protest_size_category',\n",
       " 'protest_size_category_1,000-4,999',\n",
       " 'protest_size_category_10,000-100,000',\n",
       " 'protest_size_category_100-999',\n",
       " 'protest_size_category_5,000-9,999',\n",
       " 'protest_size_category_50-99',\n",
       " 'protest_size_category_Less than 50',\n",
       " 'protest_size_category_Over 100,000',\n",
       " 'protester_id_type',\n",
       " 'protester_id_type_civil_human_rights',\n",
       " 'protester_id_type_ethnic_group',\n",
       " 'protester_id_type_locals_residents',\n",
       " 'protester_id_type_pensioners_retirees',\n",
       " 'protester_id_type_political_group',\n",
       " 'protester_id_type_prisoners',\n",
       " 'protester_id_type_protestors_generic',\n",
       " 'protester_id_type_religious_group',\n",
       " 'protester_id_type_soldiers_veterans',\n",
       " 'protester_id_type_students_youth',\n",
       " 'protester_id_type_victims_families',\n",
       " 'protester_id_type_women',\n",
       " 'protester_id_type_workers_unions',\n",
       " 'protesteridentity',\n",
       " 'protesterviolence',\n",
       " 'protestnumber',\n",
       " 'region',\n",
       " 'region_Africa',\n",
       " 'region_Asia',\n",
       " 'region_Central America',\n",
       " 'region_Europe',\n",
       " 'region_MENA',\n",
       " 'region_North America',\n",
       " 'region_Oceania',\n",
       " 'region_South America',\n",
       " 'removal_of_politician',\n",
       " 'shootings',\n",
       " 'social_restrictions',\n",
       " 'sources',\n",
       " 'start_date',\n",
       " 'target']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(mass.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummifying protest_size and protester_id_type columns \n",
    "# mass = pd.get_dummies(mass, columns=['protest_size_category', 'protester_id_type'], dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15179 entries, 0 to 15178\n",
      "Columns: 234 entries, id to protest_duration\n",
      "dtypes: float64(10), int64(212), object(12)\n",
      "memory usage: 27.1+ MB\n"
     ]
    }
   ],
   "source": [
    "mass.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will create three functions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_preds):\n",
    "    \n",
    "#     ```\n",
    "#     DOCSTRING HERE \n",
    "        \n",
    "    f1 = f1_score(y_true, y_preds)\n",
    "    \n",
    "    precision = precision_score(y_true, y_preds)\n",
    "    \n",
    "    recall = recall_score(y_true, y_preds)\n",
    "\n",
    "    # add accuracy\n",
    "\n",
    "    return f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_confusion_matrix(y_true, y_preds, title):\n",
    "    \n",
    "#     tn, fp, fn, tp = confusion_matrix(y_true, y_preds).ravel()\n",
    "#     disp = plot_confusion_matrix(model, \n",
    "#                                  X_test_sc, \n",
    "#                                  y_test, \n",
    "# #                                  display_labels=\n",
    "#                                  cmap=\"Blues\")\n",
    "    \n",
    "#     disp.ax_.set_title(title)\n",
    "#     print(title)\n",
    "#     print(disp.confusion_matrix)\n",
    "    \n",
    "#     plt.show\n",
    "    \n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_prediction_columns(model, df, features):\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    \n",
    "    X = features\n",
    "    X_sc = ss.fit_transform(X)\n",
    "    \n",
    "    predicted_column = model.predict(X_sc)\n",
    "    probability_column = model.predict_proba(X_sc)[:,1]\n",
    "    \n",
    "    return predicted_column, probability_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_response_predictor(df, features, target, model):\n",
    "    \n",
    "    X = features \n",
    "    y = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=48)\n",
    "\n",
    "    ss = StandardScaler()\n",
    "\n",
    "    X_train_sc = ss.fit_transform(X_train)\n",
    "    X_test_sc = ss.transform(X_test)\n",
    "    \n",
    "    model.fit(X_train_sc, y_train)\n",
    "    \n",
    "    y_preds_train = model.predict(X_train_sc)\n",
    "    y_preds_test = model.predict(X_test_sc)\n",
    "    \n",
    "    f1_score_train, precision_train, recall_train = evaluate_model(y_train, y_preds_train)\n",
    "    f1_score_test, precision_test, recall_test = evaluate_model(y_test, y_preds_test)\n",
    "    \n",
    "    print(f'{target}- F1_score for {model} model, train set: {f1_score_train}')\n",
    "    print(f'{target}- F1_score for {model} model, test set: {f1_score_test}')\n",
    "    print(f'{target}- Precision for {model} model, train set: {precision_train}')\n",
    "    print(f'{target}- Precision for {model} model, test set: {precision_test}')\n",
    "    print(f'{target}- Recall for {model} model, train set: {recall_train}')\n",
    "    print(f'{target}- Recall for {model} model, teset set: {recall_test}')\n",
    "    \n",
    "    predicted_column, probability_column = response_prediction_columns(model, df, features)\n",
    "    \n",
    "#     print(model)\n",
    "\n",
    "#     build_confusion_matrix(y_test, y_preds_test)\n",
    "\n",
    "    return predicted_column, probability_column, f1_score_train, f1_score_test, precision_train, precision_test, recall_train, recall_test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating variables I will pass into my function\n",
    "\n",
    "features = mass.drop(columns=['country', 'ccode', 'region', 'location','protesteridentity', 'sources',\n",
    "           'notes', 'protester_id_type', 'protest_size_category', 'start_date', 'notes_clean', 'neg', 'neu', 'pos',\n",
    "           'end_date', 'target', 'arrests', 'accomodation', 'beatings',\n",
    "           'crowddispersal', 'ignore', 'killings', 'shootings'])\n",
    "\n",
    "LogisticRegression_1 = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# lr_arrests_1 = state_response_predictor(mass, features_1, 'arrests', lr_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arrests- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.24430264357338197\n",
      "arrests- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.2722117202268431\n",
      "arrests- Precision for LogisticRegression(max_iter=1000) model, train set: 0.5690021231422505\n",
      "arrests- Precision for LogisticRegression(max_iter=1000) model, test set: 0.6605504587155964\n",
      "arrests- Recall for LogisticRegression(max_iter=1000) model, train set: 0.1555426581543819\n",
      "arrests- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.17142857142857143\n"
     ]
    }
   ],
   "source": [
    "mass['arrests_predicted'], mass['arrests_probability'], f1_score_train, f1_score_test, precision_train, precision_test, recall_train, recall_test = \\\n",
    "state_response_predictor(mass, features, 'arrests', LogisticRegression_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now that we've tested it on `arrests`, below I apply the the `state_response_predictor` function to the other six state response. This will create a column in the original `mass` DataFrame for the binary prediction and the probability for each response.*\n",
    "\n",
    "Responses: `'arrests','accomodation','beatings','crowddispersal','ignore','killings','shootings'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accomodation- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.09939759036144577\n",
      "accomodation- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.06984126984126984\n",
      "accomodation- Precision for LogisticRegression(max_iter=1000) model, train set: 0.6470588235294118\n",
      "accomodation- Precision for LogisticRegression(max_iter=1000) model, test set: 0.55\n",
      "accomodation- Recall for LogisticRegression(max_iter=1000) model, train set: 0.053833605220228384\n",
      "accomodation- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.03728813559322034\n"
     ]
    }
   ],
   "source": [
    "mass['accomodation_predicted'], mass['accomodation_probability'], f1_score_train, f1_score_test, precision_train, precision_test, recall_train, recall_test = \\\n",
    "state_response_predictor(mass, features, 'accomodation', LogisticRegression_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accomodation</th>\n",
       "      <th>accomodation_predicted</th>\n",
       "      <th>accomodation_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.921425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.609061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.596815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.540708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14736</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.609921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14737</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.840545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15133</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15149</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15152</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.611932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       accomodation  accomodation_predicted  accomodation_probability\n",
       "451               1                       1                  0.921425\n",
       "1438              1                       1                  0.609061\n",
       "1469              1                       1                  0.550764\n",
       "1679              1                       1                  0.596815\n",
       "2061              1                       1                  0.540708\n",
       "...             ...                     ...                       ...\n",
       "14736             1                       1                  0.609921\n",
       "14737             1                       1                  0.840545\n",
       "15133             1                       1                  0.524657\n",
       "15149             1                       1                  0.531713\n",
       "15152             1                       1                  0.611932\n",
       "\n",
       "[83 rows x 3 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at where accomodation is '1' and it was also correctly predicted \n",
    "\n",
    "mass[ (mass['accomodation'] == mass['accomodation_predicted']) & mass['accomodation']==1 ][['accomodation', 'accomodation_predicted', 'accomodation_probability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beatings- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.17173051519154559\n",
      "beatings- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.15568862275449102\n",
      "beatings- Precision for LogisticRegression(max_iter=1000) model, train set: 0.65\n",
      "beatings- Precision for LogisticRegression(max_iter=1000) model, test set: 0.5416666666666666\n",
      "beatings- Recall for LogisticRegression(max_iter=1000) model, train set: 0.0989345509893455\n",
      "beatings- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.09090909090909091\n"
     ]
    }
   ],
   "source": [
    "mass['beatings_predicted'], mass['beatings_probability'], f1_score_train, f1_score_test, precision_train, precision_test, recall_train, recall_test = \\\n",
    "state_response_predictor(mass, features, 'beatings', LogisticRegression_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crowddispersal- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.6446232626188734\n",
      "crowddispersal- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.624173180998196\n",
      "crowddispersal- Precision for LogisticRegression(max_iter=1000) model, train set: 0.7299536116633533\n",
      "crowddispersal- Precision for LogisticRegression(max_iter=1000) model, test set: 0.7188365650969529\n",
      "crowddispersal- Recall for LogisticRegression(max_iter=1000) model, train set: 0.5771548336389835\n",
      "crowddispersal- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.5515409139213603\n"
     ]
    }
   ],
   "source": [
    "mass['crowddispersal_predicted'], mass['crowddispersal_probability'], f1_score_train, f1_score_test, precision_train, precision_test, recall_train, recall_test = \\\n",
    "state_response_predictor(mass, features, 'crowddispersal', LogisticRegression_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ignore- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.7954094644375178\n",
      "ignore- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.7837535014005603\n",
      "ignore- Precision for LogisticRegression(max_iter=1000) model, train set: 0.745848279527036\n",
      "ignore- Precision for LogisticRegression(max_iter=1000) model, test set: 0.7324607329842932\n",
      "ignore- Recall for LogisticRegression(max_iter=1000) model, train set: 0.8520261041129155\n",
      "ignore- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.8427710843373494\n"
     ]
    }
   ],
   "source": [
    "mass['ignore_predicted'], mass['ignore_probability'], f1_score_train, f1_score_test, precision_train, precision_test, recall_train, recall_test = \\\n",
    "state_response_predictor(mass, features, 'ignore', LogisticRegression_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "killings- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.24191616766467064\n",
      "killings- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.1958762886597938\n",
      "killings- Precision for LogisticRegression(max_iter=1000) model, train set: 0.6121212121212121\n",
      "killings- Precision for LogisticRegression(max_iter=1000) model, test set: 0.475\n",
      "killings- Recall for LogisticRegression(max_iter=1000) model, train set: 0.15074626865671642\n",
      "killings- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.12337662337662338\n"
     ]
    }
   ],
   "source": [
    "mass['killings_predicted'], mass['killings_probability'], f1_score_train, f1_score_test, precision_train, precision_test, recall_train, recall_test = \\\n",
    "state_response_predictor(mass, features, 'killings', LogisticRegression_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shootings- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.24093816631130063\n",
      "shootings- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.2\n",
      "shootings- Precision for LogisticRegression(max_iter=1000) model, train set: 0.5947368421052631\n",
      "shootings- Precision for LogisticRegression(max_iter=1000) model, test set: 0.48936170212765956\n",
      "shootings- Recall for LogisticRegression(max_iter=1000) model, train set: 0.15106951871657753\n",
      "shootings- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.12568306010928962\n"
     ]
    }
   ],
   "source": [
    "mass['shootings_predicted'], mass['shootings_probability'], f1_score_train, f1_score_test, precision_train, precision_test, recall_train, recall_test = \\\n",
    "state_response_predictor(mass, features, 'shootings', LogisticRegression_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/emilynaftalin/Data_Science/General Assembly/dsi/projects/Mass-Protests/users'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building dataframe that just includes prediction! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = mass[['id','arrests', 'arrests_predicted', 'arrests_probability', 'accomodation', 'accomodation_predicted', 'accomodation_probability', \n",
    "      'beatings', 'beatings_predicted', 'beatings_probability', 'crowddispersal', 'crowddispersal_predicted', 'crowddispersal_probability', \n",
    "      'ignore', 'ignore_predicted', 'ignore_probability', 'killings', 'killings_predicted', 'killings_probability',\n",
    "      'killings', 'killings_predicted', 'killings_probability']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>arrests</th>\n",
       "      <th>arrests_predicted</th>\n",
       "      <th>arrests_probability</th>\n",
       "      <th>accomodation</th>\n",
       "      <th>accomodation_predicted</th>\n",
       "      <th>accomodation_probability</th>\n",
       "      <th>beatings</th>\n",
       "      <th>beatings_predicted</th>\n",
       "      <th>beatings_probability</th>\n",
       "      <th>...</th>\n",
       "      <th>crowddispersal_probability</th>\n",
       "      <th>ignore</th>\n",
       "      <th>ignore_predicted</th>\n",
       "      <th>ignore_probability</th>\n",
       "      <th>killings</th>\n",
       "      <th>killings_predicted</th>\n",
       "      <th>killings_probability</th>\n",
       "      <th>killings</th>\n",
       "      <th>killings_predicted</th>\n",
       "      <th>killings_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201990001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.148069</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125990</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084188</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.706858</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004661</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201990002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.132347</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064624</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.749024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201990003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.082134</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042882</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.807295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201990004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.585644</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.295309</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.123478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.123478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201990005</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.370170</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090058</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376911</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166469</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020468</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  arrests  arrests_predicted  arrests_probability  accomodation  \\\n",
       "0  201990001        0                  0             0.148069             0   \n",
       "1  201990002        0                  0             0.132347             0   \n",
       "2  201990003        0                  0             0.082134             0   \n",
       "3  201990004        0                  1             0.585644             1   \n",
       "4  201990005        1                  0             0.370170             1   \n",
       "\n",
       "   accomodation_predicted  accomodation_probability  beatings  \\\n",
       "0                       0                  0.125990         0   \n",
       "1                       0                  0.083107         0   \n",
       "2                       0                  0.041444         0   \n",
       "3                       0                  0.295309         0   \n",
       "4                       0                  0.090058         0   \n",
       "\n",
       "   beatings_predicted  beatings_probability  ...  crowddispersal_probability  \\\n",
       "0                   0              0.000192  ...                    0.084188   \n",
       "1                   0              0.000267  ...                    0.064624   \n",
       "2                   0              0.000125  ...                    0.042882   \n",
       "3                   0              0.000685  ...                    0.526179   \n",
       "4                   0              0.000518  ...                    0.376911   \n",
       "\n",
       "   ignore  ignore_predicted  ignore_probability  killings  killings_predicted  \\\n",
       "0       1                 1            0.706858         0                   0   \n",
       "1       1                 1            0.749024         0                   0   \n",
       "2       1                 1            0.807295         0                   0   \n",
       "3       0                 0            0.066220         0                   0   \n",
       "4       0                 0            0.166469         0                   0   \n",
       "\n",
       "   killings_probability  killings  killings_predicted  killings_probability  \n",
       "0              0.004661         0                   0              0.004661  \n",
       "1              0.002015         0                   0              0.002015  \n",
       "2              0.000728         0                   0              0.000728  \n",
       "3              0.123478         0                   0              0.123478  \n",
       "4              0.020468         0                   0              0.020468  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_csv('../data/04_predictions_only.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arrests- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.24430264357338197\n",
      "arrests- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.2722117202268431\n",
      "arrests- Precision for LogisticRegression(max_iter=1000) model, train set: 0.5690021231422505\n",
      "arrests- Precision for LogisticRegression(max_iter=1000) model, test set: 0.6605504587155964\n",
      "arrests- Recall for LogisticRegression(max_iter=1000) model, train set: 0.1555426581543819\n",
      "arrests- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.17142857142857143\n",
      "accomodation- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.09939759036144577\n",
      "accomodation- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.06984126984126984\n",
      "accomodation- Precision for LogisticRegression(max_iter=1000) model, train set: 0.6470588235294118\n",
      "accomodation- Precision for LogisticRegression(max_iter=1000) model, test set: 0.55\n",
      "accomodation- Recall for LogisticRegression(max_iter=1000) model, train set: 0.053833605220228384\n",
      "accomodation- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.03728813559322034\n",
      "beatings- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.17173051519154559\n",
      "beatings- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.15568862275449102\n",
      "beatings- Precision for LogisticRegression(max_iter=1000) model, train set: 0.65\n",
      "beatings- Precision for LogisticRegression(max_iter=1000) model, test set: 0.5416666666666666\n",
      "beatings- Recall for LogisticRegression(max_iter=1000) model, train set: 0.0989345509893455\n",
      "beatings- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.09090909090909091\n",
      "crowddispersal- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.6446232626188734\n",
      "crowddispersal- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.624173180998196\n",
      "crowddispersal- Precision for LogisticRegression(max_iter=1000) model, train set: 0.7299536116633533\n",
      "crowddispersal- Precision for LogisticRegression(max_iter=1000) model, test set: 0.7188365650969529\n",
      "crowddispersal- Recall for LogisticRegression(max_iter=1000) model, train set: 0.5771548336389835\n",
      "crowddispersal- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.5515409139213603\n",
      "ignore- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.7954094644375178\n",
      "ignore- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.7837535014005603\n",
      "ignore- Precision for LogisticRegression(max_iter=1000) model, train set: 0.745848279527036\n",
      "ignore- Precision for LogisticRegression(max_iter=1000) model, test set: 0.7324607329842932\n",
      "ignore- Recall for LogisticRegression(max_iter=1000) model, train set: 0.8520261041129155\n",
      "ignore- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.8427710843373494\n",
      "killings- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.24191616766467064\n",
      "killings- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.1958762886597938\n",
      "killings- Precision for LogisticRegression(max_iter=1000) model, train set: 0.6121212121212121\n",
      "killings- Precision for LogisticRegression(max_iter=1000) model, test set: 0.475\n",
      "killings- Recall for LogisticRegression(max_iter=1000) model, train set: 0.15074626865671642\n",
      "killings- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.12337662337662338\n",
      "shootings- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.24093816631130063\n",
      "shootings- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.2\n",
      "shootings- Precision for LogisticRegression(max_iter=1000) model, train set: 0.5947368421052631\n",
      "shootings- Precision for LogisticRegression(max_iter=1000) model, test set: 0.48936170212765956\n",
      "shootings- Recall for LogisticRegression(max_iter=1000) model, train set: 0.15106951871657753\n",
      "shootings- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.12568306010928962\n",
      "{'target': ['arrests', 'accomodation', 'beatings', 'crowddispersal', 'ignore', 'killings', 'shootings'], 'f1_score_train': [0.24430264357338197, 0.09939759036144577, 0.17173051519154559, 0.6446232626188734, 0.7954094644375178, 0.24191616766467064, 0.24093816631130063], 'f1_score_test': [0.2722117202268431, 0.06984126984126984, 0.15568862275449102, 0.624173180998196, 0.7837535014005603, 0.1958762886597938, 0.2], 'precision_train': [0.5690021231422505, 0.6470588235294118, 0.65, 0.7299536116633533, 0.745848279527036, 0.6121212121212121, 0.5947368421052631], 'precision_test': [0.6605504587155964, 0.55, 0.5416666666666666, 0.7188365650969529, 0.7324607329842932, 0.475, 0.48936170212765956], 'recall_train': [0.1555426581543819, 0.053833605220228384, 0.0989345509893455, 0.5771548336389835, 0.8520261041129155, 0.15074626865671642, 0.15106951871657753], 'recall_test': [0.17142857142857143, 0.03728813559322034, 0.09090909090909091, 0.5515409139213603, 0.8427710843373494, 0.12337662337662338, 0.12568306010928962]}\n"
     ]
    }
   ],
   "source": [
    "model_performance_dict = {\n",
    "    'target':[],\n",
    "#     'model':[],\n",
    "    'f1_score_train':[],\n",
    "    'f1_score_test':[],\n",
    "    'precision_train':[],\n",
    "    'precision_test':[],\n",
    "    'recall_train':[],\n",
    "    'recall_test':[] \n",
    "}\n",
    " \n",
    "targets = ['arrests','accomodation','beatings','crowddispersal','ignore','killings','shootings']    \n",
    "    \n",
    "for target in targets:\n",
    "    \n",
    "    predicted_column, probability_column, f1_score_train, f1_score_test, precision_train, precision_test, recall_train, recall_test = state_response_predictor(\n",
    "                                                                                                                                mass, \n",
    "                                                                                                                                features, \n",
    "                                                                                                                                target, \n",
    "                                                                                                                                LogisticRegression_1)\n",
    "    \n",
    "    model_performance_dict['target'].append(target)\n",
    "#     model_performance_dict['class_balance'].append(mass[classifier].value_counts(normalize=True))\n",
    "#     model_performance_dict['model'].append(model)\n",
    "    model_performance_dict['f1_score_train'].append(f1_score_train)\n",
    "    model_performance_dict['f1_score_test'].append(f1_score_test)\n",
    "    model_performance_dict['precision_train'].append(precision_train)\n",
    "    model_performance_dict['precision_test'].append(precision_test)\n",
    "    model_performance_dict['recall_train'].append(recall_train)\n",
    "    model_performance_dict['recall_test'].append(recall_test)\n",
    "    \n",
    "print(model_performance_dict)\n",
    "    \n",
    "# model_performance_df = pd.DataFrame(model_performance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>recall_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arrests</td>\n",
       "      <td>0.244303</td>\n",
       "      <td>0.272212</td>\n",
       "      <td>0.569002</td>\n",
       "      <td>0.660550</td>\n",
       "      <td>0.155543</td>\n",
       "      <td>0.171429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accomodation</td>\n",
       "      <td>0.099398</td>\n",
       "      <td>0.069841</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.053834</td>\n",
       "      <td>0.037288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beatings</td>\n",
       "      <td>0.171731</td>\n",
       "      <td>0.155689</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.098935</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crowddispersal</td>\n",
       "      <td>0.644623</td>\n",
       "      <td>0.624173</td>\n",
       "      <td>0.729954</td>\n",
       "      <td>0.718837</td>\n",
       "      <td>0.577155</td>\n",
       "      <td>0.551541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ignore</td>\n",
       "      <td>0.795409</td>\n",
       "      <td>0.783754</td>\n",
       "      <td>0.745848</td>\n",
       "      <td>0.732461</td>\n",
       "      <td>0.852026</td>\n",
       "      <td>0.842771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>killings</td>\n",
       "      <td>0.241916</td>\n",
       "      <td>0.195876</td>\n",
       "      <td>0.612121</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.150746</td>\n",
       "      <td>0.123377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>shootings</td>\n",
       "      <td>0.240938</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.594737</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.151070</td>\n",
       "      <td>0.125683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           target  f1_score_train  f1_score_test  precision_train  \\\n",
       "0         arrests        0.244303       0.272212         0.569002   \n",
       "1    accomodation        0.099398       0.069841         0.647059   \n",
       "2        beatings        0.171731       0.155689         0.650000   \n",
       "3  crowddispersal        0.644623       0.624173         0.729954   \n",
       "4          ignore        0.795409       0.783754         0.745848   \n",
       "5        killings        0.241916       0.195876         0.612121   \n",
       "6       shootings        0.240938       0.200000         0.594737   \n",
       "\n",
       "   precision_test  recall_train  recall_test  \n",
       "0        0.660550      0.155543     0.171429  \n",
       "1        0.550000      0.053834     0.037288  \n",
       "2        0.541667      0.098935     0.090909  \n",
       "3        0.718837      0.577155     0.551541  \n",
       "4        0.732461      0.852026     0.842771  \n",
       "5        0.475000      0.150746     0.123377  \n",
       "6        0.489362      0.151070     0.125683  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance_df = pd.DataFrame(model_performance_dict)\n",
    "model_performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.858818\n",
       "1    0.141182\n",
       "Name: arrests, dtype: float64"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass['arrests'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.543448\n",
       "0    0.456552\n",
       "Name: ignore, dtype: float64"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass['ignore'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.947296\n",
       "1    0.052704\n",
       "Name: beatings, dtype: float64"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass['beatings'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.938665\n",
       "1    0.061335\n",
       "Name: shootings, dtype: float64"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass['shootings'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.945714\n",
       "1    0.054286\n",
       "Name: killings, dtype: float64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass['killings'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.899796\n",
       "1    0.100204\n",
       "Name: accomodation, dtype: float64"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass['accomodation'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.686541\n",
       "1    0.313459\n",
       "Name: crowddispersal, dtype: float64"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass['crowddispersal'].value_counts(normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
