{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, LeaveOneOut, cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                            confusion_matrix, \n",
    "                            classification_report,\n",
    "                            f1_score,\n",
    "                            plot_confusion_matrix,\n",
    "                            precision_recall_curve,\n",
    "                            precision_score,\n",
    "                            recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/emilynaftalin/Data_Science/General Assembly/dsi/projects/Mass-Protests/users'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass = pd.read_csv('../data/mass_mobile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>country</th>\n",
       "      <th>ccode</th>\n",
       "      <th>region</th>\n",
       "      <th>protestnumber</th>\n",
       "      <th>protesterviolence</th>\n",
       "      <th>location</th>\n",
       "      <th>protesteridentity</th>\n",
       "      <th>sources</th>\n",
       "      <th>...</th>\n",
       "      <th>social_restrictions</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>target</th>\n",
       "      <th>notes_clean</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>protest_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>201990001</td>\n",
       "      <td>Canada</td>\n",
       "      <td>20</td>\n",
       "      <td>North America</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>national</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>1. great canadian train journeys into history;...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1990-01-15</td>\n",
       "      <td>1990-01-15</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>canada s railway passenger system was finally ...</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.8176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>201990002</td>\n",
       "      <td>Canada</td>\n",
       "      <td>20</td>\n",
       "      <td>North America</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Montreal, Quebec</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>1. autonomy s cry revived in quebec the new yo...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1990-06-25</td>\n",
       "      <td>1990-06-25</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>protestors were only identified as young peopl...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 235 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         id country  ccode         region  protestnumber  \\\n",
       "0           0  201990001  Canada     20  North America              1   \n",
       "1           1  201990002  Canada     20  North America              2   \n",
       "\n",
       "   protesterviolence          location protesteridentity  \\\n",
       "0                0.0          national       unspecified   \n",
       "1                0.0  Montreal, Quebec       unspecified   \n",
       "\n",
       "                                             sources  ... social_restrictions  \\\n",
       "0  1. great canadian train journeys into history;...  ...                   0   \n",
       "1  1. autonomy s cry revived in quebec the new yo...  ...                   0   \n",
       "\n",
       "   start_date    end_date                 target  \\\n",
       "0  1990-01-15  1990-01-15  [0, 0, 0, 0, 1, 0, 0]   \n",
       "1  1990-06-25  1990-06-25  [0, 0, 0, 0, 1, 0, 0]   \n",
       "\n",
       "                                         notes_clean    neg    neu  pos  \\\n",
       "0  canada s railway passenger system was finally ...  0.087  0.913  0.0   \n",
       "1  protestors were only identified as young peopl...  0.000  1.000  0.0   \n",
       "\n",
       "   compound  protest_duration  \n",
       "0   -0.8176                 1  \n",
       "1    0.0000                 1  \n",
       "\n",
       "[2 rows x 235 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'accomodation',\n",
       " 'arrests',\n",
       " 'beatings',\n",
       " 'ccode',\n",
       " 'compound',\n",
       " 'country',\n",
       " 'country_Afghanistan',\n",
       " 'country_Albania',\n",
       " 'country_Algeria',\n",
       " 'country_Angola',\n",
       " 'country_Argentina',\n",
       " 'country_Armenia',\n",
       " 'country_Austria',\n",
       " 'country_Azerbaijan',\n",
       " 'country_Bahrain',\n",
       " 'country_Bangladesh',\n",
       " 'country_Belarus',\n",
       " 'country_Belgium',\n",
       " 'country_Benin',\n",
       " 'country_Bolivia',\n",
       " 'country_Bosnia',\n",
       " 'country_Botswana',\n",
       " 'country_Brazil',\n",
       " 'country_Bulgaria',\n",
       " 'country_Burkina Faso',\n",
       " 'country_Burundi',\n",
       " 'country_Cambodia',\n",
       " 'country_Cameroon',\n",
       " 'country_Canada',\n",
       " 'country_Cape Verde',\n",
       " 'country_Central African Republic',\n",
       " 'country_Chad',\n",
       " 'country_Chile',\n",
       " 'country_China',\n",
       " 'country_Colombia',\n",
       " 'country_Comoros',\n",
       " 'country_Congo Brazzaville',\n",
       " 'country_Congo Kinshasa',\n",
       " 'country_Costa Rica',\n",
       " 'country_Croatia',\n",
       " 'country_Cuba',\n",
       " 'country_Cyprus',\n",
       " 'country_Czech Republic',\n",
       " 'country_Czechoslovakia',\n",
       " 'country_Denmark',\n",
       " 'country_Djibouti',\n",
       " 'country_Dominican Republic',\n",
       " 'country_Ecuador',\n",
       " 'country_Egypt',\n",
       " 'country_El Salvador',\n",
       " 'country_Equatorial Guinea',\n",
       " 'country_Eritrea',\n",
       " 'country_Estonia',\n",
       " 'country_Ethiopia',\n",
       " 'country_Finland',\n",
       " 'country_France',\n",
       " 'country_Gabon',\n",
       " 'country_Gambia',\n",
       " 'country_Georgia',\n",
       " 'country_Germany',\n",
       " 'country_Germany East',\n",
       " 'country_Germany West',\n",
       " 'country_Ghana',\n",
       " 'country_Greece',\n",
       " 'country_Guatemala',\n",
       " 'country_Guinea',\n",
       " 'country_Guinea-Bissau',\n",
       " 'country_Guyana',\n",
       " 'country_Haiti',\n",
       " 'country_Honduras',\n",
       " 'country_Hungary',\n",
       " 'country_India',\n",
       " 'country_Indonesia',\n",
       " 'country_Iran',\n",
       " 'country_Iraq',\n",
       " 'country_Ireland',\n",
       " 'country_Italy',\n",
       " 'country_Ivory Coast',\n",
       " 'country_Jamaica',\n",
       " 'country_Japan',\n",
       " 'country_Jordan',\n",
       " 'country_Kazakhstan',\n",
       " 'country_Kenya',\n",
       " 'country_Kosovo',\n",
       " 'country_Kuwait',\n",
       " 'country_Kyrgyzstan',\n",
       " 'country_Laos',\n",
       " 'country_Latvia',\n",
       " 'country_Lebanon',\n",
       " 'country_Lesotho',\n",
       " 'country_Liberia',\n",
       " 'country_Libya',\n",
       " 'country_Lithuania',\n",
       " 'country_Luxembourg',\n",
       " 'country_Macedonia',\n",
       " 'country_Madagascar',\n",
       " 'country_Malawi',\n",
       " 'country_Malaysia',\n",
       " 'country_Mali',\n",
       " 'country_Mauritania',\n",
       " 'country_Mauritius',\n",
       " 'country_Mexico',\n",
       " 'country_Moldova',\n",
       " 'country_Mongolia',\n",
       " 'country_Montenegro',\n",
       " 'country_Morocco',\n",
       " 'country_Mozambique',\n",
       " 'country_Myanmar',\n",
       " 'country_Namibia',\n",
       " 'country_Nepal',\n",
       " 'country_Netherlands',\n",
       " 'country_Nicaragua',\n",
       " 'country_Niger',\n",
       " 'country_Nigeria',\n",
       " 'country_North Korea',\n",
       " 'country_Norway',\n",
       " 'country_Oman',\n",
       " 'country_Pakistan',\n",
       " 'country_Panama',\n",
       " 'country_Papua New Guinea',\n",
       " 'country_Paraguay',\n",
       " 'country_Peru',\n",
       " 'country_Philippines',\n",
       " 'country_Poland',\n",
       " 'country_Portugal',\n",
       " 'country_Qatar',\n",
       " 'country_Romania',\n",
       " 'country_Russia',\n",
       " 'country_Rwanda',\n",
       " 'country_Saudi Arabia',\n",
       " 'country_Senegal',\n",
       " 'country_Serbia',\n",
       " 'country_Serbia and Montenegro',\n",
       " 'country_Sierra Leone',\n",
       " 'country_Singapore',\n",
       " 'country_Slovak Republic',\n",
       " 'country_Slovenia',\n",
       " 'country_Somalia',\n",
       " 'country_South Africa',\n",
       " 'country_South Korea',\n",
       " 'country_South Sudan',\n",
       " 'country_Spain',\n",
       " 'country_Sri Lanka',\n",
       " 'country_Sudan',\n",
       " 'country_Suriname',\n",
       " 'country_Swaziland',\n",
       " 'country_Sweden',\n",
       " 'country_Switzerland',\n",
       " 'country_Syria',\n",
       " 'country_Taiwan',\n",
       " 'country_Tajikistan',\n",
       " 'country_Tanzania',\n",
       " 'country_Thailand',\n",
       " 'country_Timor Leste',\n",
       " 'country_Togo',\n",
       " 'country_Tunisia',\n",
       " 'country_Turkey',\n",
       " 'country_Turkmenistan',\n",
       " 'country_USSR',\n",
       " 'country_Uganda',\n",
       " 'country_Ukraine',\n",
       " 'country_United Arab Emirate',\n",
       " 'country_United Kingdom',\n",
       " 'country_Uruguay',\n",
       " 'country_Uzbekistan',\n",
       " 'country_Venezuela',\n",
       " 'country_Vietnam',\n",
       " 'country_Yemen',\n",
       " 'country_Yugoslavia',\n",
       " 'country_Zambia',\n",
       " 'country_Zimbabwe',\n",
       " 'crowddispersal',\n",
       " 'end_date',\n",
       " 'id',\n",
       " 'ignore',\n",
       " 'killings',\n",
       " 'labor_wage_dispute',\n",
       " 'land_farm_issue',\n",
       " 'location',\n",
       " 'neg',\n",
       " 'neu',\n",
       " 'notes',\n",
       " 'notes_clean',\n",
       " 'partipants_number',\n",
       " 'police_brutality',\n",
       " 'political_behavior_process',\n",
       " 'pop_density',\n",
       " 'pop_female',\n",
       " 'pop_male',\n",
       " 'pop_total',\n",
       " 'pos',\n",
       " 'price increases_tax_policy',\n",
       " 'prosperity_2020',\n",
       " 'protest_duration',\n",
       " 'protest_size_category',\n",
       " 'protest_size_category_1,000-4,999',\n",
       " 'protest_size_category_10,000-100,000',\n",
       " 'protest_size_category_100-999',\n",
       " 'protest_size_category_5,000-9,999',\n",
       " 'protest_size_category_50-99',\n",
       " 'protest_size_category_Less than 50',\n",
       " 'protest_size_category_Over 100,000',\n",
       " 'protester_id_type',\n",
       " 'protester_id_type_civil_human_rights',\n",
       " 'protester_id_type_ethnic_group',\n",
       " 'protester_id_type_locals_residents',\n",
       " 'protester_id_type_pensioners_retirees',\n",
       " 'protester_id_type_political_group',\n",
       " 'protester_id_type_prisoners',\n",
       " 'protester_id_type_protestors_generic',\n",
       " 'protester_id_type_religious_group',\n",
       " 'protester_id_type_soldiers_veterans',\n",
       " 'protester_id_type_students_youth',\n",
       " 'protester_id_type_victims_families',\n",
       " 'protester_id_type_women',\n",
       " 'protester_id_type_workers_unions',\n",
       " 'protesteridentity',\n",
       " 'protesterviolence',\n",
       " 'protestnumber',\n",
       " 'region',\n",
       " 'region_Africa',\n",
       " 'region_Asia',\n",
       " 'region_Central America',\n",
       " 'region_Europe',\n",
       " 'region_MENA',\n",
       " 'region_North America',\n",
       " 'region_Oceania',\n",
       " 'region_South America',\n",
       " 'removal_of_politician',\n",
       " 'shootings',\n",
       " 'social_restrictions',\n",
       " 'sources',\n",
       " 'start_date',\n",
       " 'target']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(mass.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummifying protest_size and protester_id_type columns \n",
    "mass = pd.get_dummies(mass, columns=['protest_size_category', 'protester_id_type'], dummy_na=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, attempting a Logistic Regression for each state response, starting with `arrests`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = mass.drop(columns=['country','ccode','location','region','sources','notes', 'protesteridentity','start_date','end_date', \n",
    "#                               'arrests','accomodation','beatings','crowddispersal','ignore','killings','shootings'])\n",
    "# y = mass['arrests']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=48)\n",
    "\n",
    "# ss = StandardScaler()\n",
    "\n",
    "# X_train_sc = ss.fit_transform(X_train)\n",
    "# X_test_sc = ss.transform(X_test)\n",
    "\n",
    "# lr = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# lr.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr.score(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have created and evaluated the Logistic Regression model using the training and test set, I will scale the entire `X` set and make predictions for each row in the DataFrame. This will allow me to add two new columns: \n",
    "+ **`arrests_predicted`**: column of 0s and 1s indicating whether the protest is predicted to have arrests as one of the state responses. \n",
    "+ **`arrests_probability`**: the calculated probability that the protest will have arrests as one of the state responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ss = StandardScaler()\n",
    "\n",
    "# X_sc = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrests_predicted_all = lr.predict(X_sc)\n",
    "\n",
    "# arrests_probability_all = lr.predict_proba(X_sc)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mass['arrests_predicted'] = arrests_predicted_all\n",
    "\n",
    "# mass['arrests_probability'] = arrests_probability_all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking out how it looks \n",
    "# mass[['arrests', 'arrests_predicted','arrests_probability']][22:33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15225 entries, 0 to 15224\n",
      "Columns: 227 entries, id to protester_id_type_nan\n",
      "dtypes: datetime64[ns](2), float64(6), int32(180), int64(11), object(6), uint8(22)\n",
      "memory usage: 13.8+ MB\n"
     ]
    }
   ],
   "source": [
    "mass.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will create three functions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_preds):\n",
    "    \n",
    "    ```\n",
    "    DOCSTRING HERE \n",
    "        \n",
    "    f1 = f1_score(y_true, y_preds)\n",
    "    \n",
    "    precision = precision_score(y_true, y_preds)\n",
    "    \n",
    "    recall = recall_score(y_true, y_preds)\n",
    "\n",
    "    # add accuracy\n",
    "\n",
    "    return f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_confusion_matrix(y_true, y_preds, title):\n",
    "    \n",
    "#     tn, fp, fn, tp = confusion_matrix(y_true, y_preds).ravel()\n",
    "#     disp = plot_confusion_matrix(model, \n",
    "#                                  X_test_sc, \n",
    "#                                  y_test, \n",
    "# #                                  display_labels=\n",
    "#                                  cmap=\"Blues\")\n",
    "    \n",
    "#     disp.ax_.set_title(title)\n",
    "#     print(title)\n",
    "#     print(disp.confusion_matrix)\n",
    "    \n",
    "#     plt.show\n",
    "    \n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass['arrests_predction'], mass['arrest_prob'] = response_prediction_columns(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_prediction_columns(model, df, features):\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    \n",
    "    X = features\n",
    "    X_sc = ss.fit_transform(X)\n",
    "    \n",
    "    predicted_column = model.predict(X_sc)\n",
    "    probability_column = model.predict_proba(X_sc)[:,1]\n",
    "    \n",
    "    return predicted_column, probability_column\n",
    "\n",
    "# ss = StandardScaler()\n",
    "\n",
    "# X_sc = ss.fit_transform(X)\n",
    "\n",
    "# arrests_predicted_all = lr.predict(X_sc)\n",
    "\n",
    "# arrests_probability_all = lr.predict_proba(X_sc)[:,1]\n",
    "\n",
    "# mass['arrests_predicted'] = arrests_predicted_all\n",
    "\n",
    "# mass['arrests_probability'] = arrests_probability_all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_response_predictor(df, features, target, model):\n",
    "    \n",
    "    X = features \n",
    "    y = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=48)\n",
    "\n",
    "    ss = StandardScaler()\n",
    "\n",
    "    X_train_sc = ss.fit_transform(X_train)\n",
    "    X_test_sc = ss.transform(X_test)\n",
    "    \n",
    "    model.fit(X_train_sc, y_train)\n",
    "    \n",
    "    y_preds_train = model.predict(X_train_sc)\n",
    "    y_preds_test = model.predict(X_test_sc)\n",
    "    \n",
    "    f1_score_train, precision_train, recall_train = evaluate_model(y_train, y_preds_train)\n",
    "    f1_score_test, precision_test, recall_test = evaluate_model(y_test, y_preds_test)\n",
    "    \n",
    "    print(f'{target}- F1_score for {model} model, train set: {f1_score_train}')\n",
    "    print(f'{target}- F1_score for {model} model, test set: {f1_score_test}')\n",
    "    print(f'{target}- Precision for {model} model, train set: {precision_train}')\n",
    "    print(f'{target}- Precision for {model} model, test set: {precision_test}')\n",
    "    print(f'{target}- Recall for {model} model, train set: {recall_train}')\n",
    "    print(f'{target}- Recall for {model} model, teset set: {recall_test}')\n",
    "    \n",
    "    predicted_column, probability_column = response_prediction_columns(model, df, features)\n",
    "    \n",
    "#     print(model)\n",
    "\n",
    "#     build_confusion_matrix(y_test, y_preds_test)\n",
    "\n",
    "    return predicted_column, probability_column, f1_score_train, f1_score_test, precision_train, precision_test, recall_train, recall_test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arrests- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.1408450704225352\n",
      "arrests- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.1310211946050096\n",
      "arrests- Precision for LogisticRegression(max_iter=1000) model, train set: 0.5895196506550219\n",
      "arrests- Precision for LogisticRegression(max_iter=1000) model, test set: 0.5666666666666667\n",
      "arrests- Recall for LogisticRegression(max_iter=1000) model, train set: 0.07997630331753554\n",
      "arrests- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.07407407407407407\n",
      "LogisticRegression(max_iter=1000)\n"
     ]
    }
   ],
   "source": [
    "mass['arrests_predicted'], mass['arrests_probability'], f1_score_train, f1_score_test, precision_train, precision_test, recall_train, recall_test = \\\n",
    "state_response_predictor(mass, features_1, 'arrests', LogisticRegression_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_response_predictor(mass, features_1, 'arrests', LogisticRegression_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mass.drop(columns=['arrests_predicted','arrests_probability'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mass['arrests_predicted'], mass['arrests_probability'] = response_prediction_columns(lr_arrests_1, mass, features_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Implementing three above functions for each state response. Will be tweaking the model throughout._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_1 = mass.drop(columns=['country','ccode','location','region','sources','notes', 'protesteridentity','start_date','end_date', \n",
    "                              'arrests','accomodation','beatings','crowddispersal','ignore','killings','shootings'])\n",
    "\n",
    "LogisticRegression_1 = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# lr_arrests_1 = state_response_predictor(mass, features_1, 'arrests', lr_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_arrests_1, f1_score_train_arrests, f1_score_test_arrests, precision_train, precision_test, recall_train, recall_test = state_response_predictor(mass, \n",
    "#                                                                                                                                    features_1, \n",
    "#                                                                                                                                    'arrests', \n",
    "#                                                                                                                                    LogisticRegression_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (sorted(list(mass.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mass['arrests_predicted'], mass['arrests_probability'] = response_prediction_columns(lr_arrests_1, mass, features_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mass[['arrests', 'arrests_predicted', 'arrests_probability']][22:33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mass[['arrests', 'arrests_predicted', 'arrests_probability', 'accomodation', 'accomodation_predicted', 'accomodation_probability']][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accomodation</th>\n",
       "      <th>accomodation_predicted</th>\n",
       "      <th>accomodation_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.516572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.549651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.532235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7070</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.586965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10393</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.577717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10631</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.601283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10633</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.627362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10635</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.593241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10661</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10664</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.501448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10667</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.526575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14781</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.567069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15179</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.532861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15195</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.518128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15198</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.548631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accomodation  accomodation_predicted  accomodation_probability\n",
       "2112              1                       1                  0.516572\n",
       "2186              1                       1                  0.549651\n",
       "2474              1                       1                  0.532235\n",
       "7070              1                       1                  0.586965\n",
       "10393             1                       1                  0.577717\n",
       "10631             1                       1                  0.601283\n",
       "10633             1                       1                  0.627362\n",
       "10635             1                       1                  0.593241\n",
       "10661             1                       1                  0.506783\n",
       "10664             1                       1                  0.501448\n",
       "10667             1                       1                  0.526575\n",
       "14781             1                       1                  0.567069\n",
       "15179             1                       1                  0.532861\n",
       "15195             1                       1                  0.518128\n",
       "15198             1                       1                  0.548631"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass[ (mass['accomodation'] == mass['accomodation_predicted']) & mass['accomodation']==1 ][['accomodation', 'accomodation_predicted', 'accomodation_probability']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now that we've tested it on `arrests`, below I apply the the `state_response_predictor` function to the other six state response. This will create a column in the original `mass` DataFrame for the binary prediction and the probability for each response.*\n",
    "\n",
    "Responses: `'arrests','accomodation','beatings','crowddispersal','ignore','killings','shootings'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accomodation- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.03843074459567654\n",
      "accomodation- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.053571428571428575\n",
      "accomodation- Precision for LogisticRegression(max_iter=1000) model, train set: 0.5454545454545454\n",
      "accomodation- Precision for LogisticRegression(max_iter=1000) model, test set: 0.6\n",
      "accomodation- Recall for LogisticRegression(max_iter=1000) model, train set: 0.01991701244813278\n",
      "accomodation- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.028037383177570093\n",
      "LogisticRegression(max_iter=1000)\n"
     ]
    }
   ],
   "source": [
    "mass['accomodation_predicted'], mass['accomodation_probability'], f1_score_train, f1_score_test, precision_train, precision_test, recall_train, recall_test = \\\n",
    "state_response_predictor(mass, features_1, 'accomodation', LogisticRegression_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beatings- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.11881188118811882\n",
      "beatings- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.14444444444444446\n",
      "beatings- Precision for LogisticRegression(max_iter=1000) model, train set: 0.65625\n",
      "beatings- Precision for LogisticRegression(max_iter=1000) model, test set: 0.65\n",
      "beatings- Recall for LogisticRegression(max_iter=1000) model, train set: 0.06531881804043546\n",
      "beatings- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.08125\n",
      "LogisticRegression(max_iter=1000)\n"
     ]
    }
   ],
   "source": [
    "mass['beatings_predicted'], mass['beatings_probability'], f1_score_train, f1_score_test, precision_train, precision_test, recall_train, recall_test = \\\n",
    "state_response_predictor(mass, features_1, 'beatings', LogisticRegression_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crowddispersal- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.657023000144655\n",
      "crowddispersal- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.6085946573751453\n",
      "crowddispersal- Precision for LogisticRegression(max_iter=1000) model, train set: 0.7373376623376623\n",
      "crowddispersal- Precision for LogisticRegression(max_iter=1000) model, test set: 0.6649746192893401\n",
      "crowddispersal- Recall for LogisticRegression(max_iter=1000) model, train set: 0.5924863031567963\n",
      "crowddispersal- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.5610278372591007\n",
      "LogisticRegression(max_iter=1000)\n"
     ]
    }
   ],
   "source": [
    "mass['crowddispersal_predicted'], mass['crowddispersal_probability'], f1_score_train, f1_score_test, precision_train, precision_test, recall_train, recall_test = \\\n",
    "state_response_predictor(mass, features_1, 'crowddispersal', LogisticRegression_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ignore- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.794378288562725\n",
      "ignore- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.7804335742078933\n",
      "ignore- Precision for LogisticRegression(max_iter=1000) model, train set: 0.7336317135549872\n",
      "ignore- Precision for LogisticRegression(max_iter=1000) model, test set: 0.7225939269171384\n",
      "ignore- Recall for LogisticRegression(max_iter=1000) model, train set: 0.8660929951690821\n",
      "ignore- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.8483383685800604\n",
      "LogisticRegression(max_iter=1000)\n"
     ]
    }
   ],
   "source": [
    "mass['ignore_predicted'], mass['ignore_probability'], f1_score_train, f1_score_test, precision_train, precision_test, recall_train, recall_test = \\\n",
    "state_response_predictor(mass, features_1, 'ignore', LogisticRegression_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "killings- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.17120622568093383\n",
      "killings- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.12435233160621761\n",
      "killings- Precision for LogisticRegression(max_iter=1000) model, train set: 0.5789473684210527\n",
      "killings- Precision for LogisticRegression(max_iter=1000) model, test set: 0.48\n",
      "killings- Recall for LogisticRegression(max_iter=1000) model, train set: 0.1004566210045662\n",
      "killings- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.07142857142857142\n",
      "LogisticRegression(max_iter=1000)\n"
     ]
    }
   ],
   "source": [
    "mass['killings_predicted'], mass['killings_probability'], f1_score_train, f1_score_test, precision_train, precision_test, recall_train, recall_test = \\\n",
    "state_response_predictor(mass, features_1, 'killings', LogisticRegression_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shootings- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.21176470588235294\n",
      "shootings- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.1722488038277512\n",
      "shootings- Precision for LogisticRegression(max_iter=1000) model, train set: 0.5689655172413793\n",
      "shootings- Precision for LogisticRegression(max_iter=1000) model, test set: 0.4864864864864865\n",
      "shootings- Recall for LogisticRegression(max_iter=1000) model, train set: 0.13009198423127463\n",
      "shootings- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.10465116279069768\n",
      "LogisticRegression(max_iter=1000)\n"
     ]
    }
   ],
   "source": [
    "mass['shootings_predicted'], mass['shootings_probability'], f1_score_train, f1_score_test, precision_train, precision_test, recall_train, recall_test = \\\n",
    "state_response_predictor(mass, features_1, 'shootings', LogisticRegression_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'country',\n",
       " 'ccode',\n",
       " 'region',\n",
       " 'protestnumber',\n",
       " 'protesterviolence',\n",
       " 'location',\n",
       " 'protesteridentity',\n",
       " 'sources',\n",
       " 'notes',\n",
       " 'partipants_number',\n",
       " 'pop_male',\n",
       " 'pop_female',\n",
       " 'pop_total',\n",
       " 'pop_density',\n",
       " 'prosperity_2020',\n",
       " 'country_Afghanistan',\n",
       " 'country_Albania',\n",
       " 'country_Algeria',\n",
       " 'country_Angola',\n",
       " 'country_Argentina',\n",
       " 'country_Armenia',\n",
       " 'country_Austria',\n",
       " 'country_Azerbaijan',\n",
       " 'country_Bahrain',\n",
       " 'country_Bangladesh',\n",
       " 'country_Belarus',\n",
       " 'country_Belgium',\n",
       " 'country_Benin',\n",
       " 'country_Bolivia',\n",
       " 'country_Bosnia',\n",
       " 'country_Botswana',\n",
       " 'country_Brazil',\n",
       " 'country_Bulgaria',\n",
       " 'country_Burkina Faso',\n",
       " 'country_Burundi',\n",
       " 'country_Cambodia',\n",
       " 'country_Cameroon',\n",
       " 'country_Canada',\n",
       " 'country_Cape Verde',\n",
       " 'country_Central African Republic',\n",
       " 'country_Chad',\n",
       " 'country_Chile',\n",
       " 'country_China',\n",
       " 'country_Colombia',\n",
       " 'country_Comoros',\n",
       " 'country_Congo Brazzaville',\n",
       " 'country_Congo Kinshasa',\n",
       " 'country_Costa Rica',\n",
       " 'country_Croatia',\n",
       " 'country_Cuba',\n",
       " 'country_Cyprus',\n",
       " 'country_Czech Republic',\n",
       " 'country_Czechoslovakia',\n",
       " 'country_Denmark',\n",
       " 'country_Djibouti',\n",
       " 'country_Dominican Republic',\n",
       " 'country_Ecuador',\n",
       " 'country_Egypt',\n",
       " 'country_El Salvador',\n",
       " 'country_Equatorial Guinea',\n",
       " 'country_Eritrea',\n",
       " 'country_Estonia',\n",
       " 'country_Ethiopia',\n",
       " 'country_Finland',\n",
       " 'country_France',\n",
       " 'country_Gabon',\n",
       " 'country_Gambia',\n",
       " 'country_Georgia',\n",
       " 'country_Germany',\n",
       " 'country_Germany East',\n",
       " 'country_Germany West',\n",
       " 'country_Ghana',\n",
       " 'country_Greece',\n",
       " 'country_Guatemala',\n",
       " 'country_Guinea',\n",
       " 'country_Guinea-Bissau',\n",
       " 'country_Guyana',\n",
       " 'country_Haiti',\n",
       " 'country_Honduras',\n",
       " 'country_Hungary',\n",
       " 'country_India',\n",
       " 'country_Indonesia',\n",
       " 'country_Iran',\n",
       " 'country_Iraq',\n",
       " 'country_Ireland',\n",
       " 'country_Italy',\n",
       " 'country_Ivory Coast',\n",
       " 'country_Jamaica',\n",
       " 'country_Japan',\n",
       " 'country_Jordan',\n",
       " 'country_Kazakhstan',\n",
       " 'country_Kenya',\n",
       " 'country_Kosovo',\n",
       " 'country_Kuwait',\n",
       " 'country_Kyrgyzstan',\n",
       " 'country_Laos',\n",
       " 'country_Latvia',\n",
       " 'country_Lebanon',\n",
       " 'country_Lesotho',\n",
       " 'country_Liberia',\n",
       " 'country_Libya',\n",
       " 'country_Lithuania',\n",
       " 'country_Luxembourg',\n",
       " 'country_Macedonia',\n",
       " 'country_Madagascar',\n",
       " 'country_Malawi',\n",
       " 'country_Malaysia',\n",
       " 'country_Mali',\n",
       " 'country_Mauritania',\n",
       " 'country_Mauritius',\n",
       " 'country_Mexico',\n",
       " 'country_Moldova',\n",
       " 'country_Mongolia',\n",
       " 'country_Montenegro',\n",
       " 'country_Morocco',\n",
       " 'country_Mozambique',\n",
       " 'country_Myanmar',\n",
       " 'country_Namibia',\n",
       " 'country_Nepal',\n",
       " 'country_Netherlands',\n",
       " 'country_Nicaragua',\n",
       " 'country_Niger',\n",
       " 'country_Nigeria',\n",
       " 'country_North Korea',\n",
       " 'country_Norway',\n",
       " 'country_Oman',\n",
       " 'country_Pakistan',\n",
       " 'country_Panama',\n",
       " 'country_Papua New Guinea',\n",
       " 'country_Paraguay',\n",
       " 'country_Peru',\n",
       " 'country_Philippines',\n",
       " 'country_Poland',\n",
       " 'country_Portugal',\n",
       " 'country_Qatar',\n",
       " 'country_Romania',\n",
       " 'country_Russia',\n",
       " 'country_Rwanda',\n",
       " 'country_Saudi Arabia',\n",
       " 'country_Senegal',\n",
       " 'country_Serbia',\n",
       " 'country_Serbia and Montenegro',\n",
       " 'country_Sierra Leone',\n",
       " 'country_Singapore',\n",
       " 'country_Slovak Republic',\n",
       " 'country_Slovenia',\n",
       " 'country_Somalia',\n",
       " 'country_South Africa',\n",
       " 'country_South Korea',\n",
       " 'country_South Sudan',\n",
       " 'country_Spain',\n",
       " 'country_Sri Lanka',\n",
       " 'country_Sudan',\n",
       " 'country_Suriname',\n",
       " 'country_Swaziland',\n",
       " 'country_Sweden',\n",
       " 'country_Switzerland',\n",
       " 'country_Syria',\n",
       " 'country_Taiwan',\n",
       " 'country_Tajikistan',\n",
       " 'country_Tanzania',\n",
       " 'country_Thailand',\n",
       " 'country_Timor Leste',\n",
       " 'country_Togo',\n",
       " 'country_Tunisia',\n",
       " 'country_Turkey',\n",
       " 'country_Turkmenistan',\n",
       " 'country_USSR',\n",
       " 'country_Uganda',\n",
       " 'country_Ukraine',\n",
       " 'country_United Arab Emirate',\n",
       " 'country_United Kingdom',\n",
       " 'country_Uruguay',\n",
       " 'country_Uzbekistan',\n",
       " 'country_Venezuela',\n",
       " 'country_Vietnam',\n",
       " 'country_Yemen',\n",
       " 'country_Yugoslavia',\n",
       " 'country_Zambia',\n",
       " 'country_Zimbabwe',\n",
       " 'region_Africa',\n",
       " 'region_Asia',\n",
       " 'region_Central America',\n",
       " 'region_Europe',\n",
       " 'region_MENA',\n",
       " 'region_North America',\n",
       " 'region_Oceania',\n",
       " 'region_South America',\n",
       " 'arrests',\n",
       " 'accomodation',\n",
       " 'beatings',\n",
       " 'crowddispersal',\n",
       " 'ignore',\n",
       " 'killings',\n",
       " 'shootings',\n",
       " 'labor_wage_dispute',\n",
       " 'land_farm_issue',\n",
       " 'police_brutality',\n",
       " 'political_behavior_process',\n",
       " 'price increases_tax_policy',\n",
       " 'removal_of_politician',\n",
       " 'social_restrictions',\n",
       " 'start_date',\n",
       " 'end_date',\n",
       " 'protest_size_category_1,000-4,999',\n",
       " 'protest_size_category_10,000-100,000',\n",
       " 'protest_size_category_100-999',\n",
       " 'protest_size_category_5,000-9,999',\n",
       " 'protest_size_category_50-99',\n",
       " 'protest_size_category_Less than 50',\n",
       " 'protest_size_category_Over 100,000',\n",
       " 'protest_size_category_nan',\n",
       " 'protester_id_type_civil_human_rights',\n",
       " 'protester_id_type_ethnic_group',\n",
       " 'protester_id_type_locals_residents',\n",
       " 'protester_id_type_pensioners_retirees',\n",
       " 'protester_id_type_political_group',\n",
       " 'protester_id_type_prisoners',\n",
       " 'protester_id_type_protestors_generic',\n",
       " 'protester_id_type_religious_group',\n",
       " 'protester_id_type_soldiers_veterans',\n",
       " 'protester_id_type_students_youth',\n",
       " 'protester_id_type_victims_families',\n",
       " 'protester_id_type_women',\n",
       " 'protester_id_type_workers_unions',\n",
       " 'protester_id_type_nan',\n",
       " 'arrests_predicted',\n",
       " 'arrests_probability',\n",
       " 'accomodation_predicted',\n",
       " 'accomodation_probability',\n",
       " 'beatings_predicted',\n",
       " 'beatings_probability',\n",
       " 'crowddispersal_predicted',\n",
       " 'crowddispersal_probability',\n",
       " 'ignore_predicted',\n",
       " 'ignore_probability',\n",
       " 'killings_predicted',\n",
       " 'killings_probability',\n",
       " 'shootings_predicted',\n",
       " 'shootings_probability']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(list(mass.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/emilynaftalin/Data_Science/General Assembly/dsi/projects/Mass-Protests/users'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = mass[['id','arrests', 'arrests_predicted', 'arrests_probability', 'accomodation', 'accomodation_predicted', 'accomodation_probability', \n",
    "      'beatings', 'beatings_predicted', 'beatings_probability', 'crowddispersal', 'crowddispersal_predicted', 'crowddispersal_probability', \n",
    "      'ignore', 'ignore_predicted', 'ignore_probability', 'killings', 'killings_predicted', 'killings_probability',\n",
    "      'killings', 'killings_predicted', 'killings_probability']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>arrests</th>\n",
       "      <th>arrests_predicted</th>\n",
       "      <th>arrests_probability</th>\n",
       "      <th>accomodation</th>\n",
       "      <th>accomodation_predicted</th>\n",
       "      <th>accomodation_probability</th>\n",
       "      <th>beatings</th>\n",
       "      <th>beatings_predicted</th>\n",
       "      <th>beatings_probability</th>\n",
       "      <th>...</th>\n",
       "      <th>crowddispersal_probability</th>\n",
       "      <th>ignore</th>\n",
       "      <th>ignore_predicted</th>\n",
       "      <th>ignore_probability</th>\n",
       "      <th>killings</th>\n",
       "      <th>killings_predicted</th>\n",
       "      <th>killings_probability</th>\n",
       "      <th>killings</th>\n",
       "      <th>killings_predicted</th>\n",
       "      <th>killings_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201990001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.104568</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.174497</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078412</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.755349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201990002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.191000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.117303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104708</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.692979</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201990003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.205189</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.052175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096429</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.687309</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008844</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201990004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533197</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.156799</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379723</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.103104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.103104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201990005</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.421843</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.085363</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452339</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138899</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  arrests  arrests_predicted  arrests_probability  accomodation  \\\n",
       "0  201990001        0                  0             0.104568             0   \n",
       "1  201990002        0                  0             0.191000             0   \n",
       "2  201990003        0                  0             0.205189             0   \n",
       "3  201990004        0                  1             0.533197             1   \n",
       "4  201990005        1                  0             0.421843             1   \n",
       "\n",
       "   accomodation_predicted  accomodation_probability  beatings  \\\n",
       "0                       0                  0.174497         0   \n",
       "1                       0                  0.117303         0   \n",
       "2                       0                  0.052175         0   \n",
       "3                       0                  0.156799         0   \n",
       "4                       0                  0.085363         0   \n",
       "\n",
       "   beatings_predicted  beatings_probability  ...  crowddispersal_probability  \\\n",
       "0                   0              0.000192  ...                    0.078412   \n",
       "1                   0              0.000307  ...                    0.104708   \n",
       "2                   0              0.000267  ...                    0.096429   \n",
       "3                   0              0.000359  ...                    0.379723   \n",
       "4                   0              0.000595  ...                    0.452339   \n",
       "\n",
       "   ignore  ignore_predicted  ignore_probability  killings  killings_predicted  \\\n",
       "0       1                 1            0.755349         0                   0   \n",
       "1       1                 1            0.692979         0                   0   \n",
       "2       1                 1            0.687309         0                   0   \n",
       "3       0                 0            0.055110         0                   0   \n",
       "4       0                 0            0.138899         0                   0   \n",
       "\n",
       "   killings_probability  killings  killings_predicted  killings_probability  \n",
       "0              0.006260         0                   0              0.006260  \n",
       "1              0.007246         0                   0              0.007246  \n",
       "2              0.008844         0                   0              0.008844  \n",
       "3              0.103104         0                   0              0.103104  \n",
       "4              0.041307         0                   0              0.041307  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_csv('../data/04_predictions_only.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arrests- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.1408450704225352\n",
      "arrests- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.1310211946050096\n",
      "arrests- Precision for LogisticRegression(max_iter=1000) model, train set: 0.5895196506550219\n",
      "arrests- Precision for LogisticRegression(max_iter=1000) model, test set: 0.5666666666666667\n",
      "arrests- Recall for LogisticRegression(max_iter=1000) model, train set: 0.07997630331753554\n",
      "arrests- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.07407407407407407\n",
      "LogisticRegression(max_iter=1000)\n",
      "accomodation- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.03843074459567654\n",
      "accomodation- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.053571428571428575\n",
      "accomodation- Precision for LogisticRegression(max_iter=1000) model, train set: 0.5454545454545454\n",
      "accomodation- Precision for LogisticRegression(max_iter=1000) model, test set: 0.6\n",
      "accomodation- Recall for LogisticRegression(max_iter=1000) model, train set: 0.01991701244813278\n",
      "accomodation- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.028037383177570093\n",
      "LogisticRegression(max_iter=1000)\n",
      "beatings- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.11881188118811882\n",
      "beatings- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.14444444444444446\n",
      "beatings- Precision for LogisticRegression(max_iter=1000) model, train set: 0.65625\n",
      "beatings- Precision for LogisticRegression(max_iter=1000) model, test set: 0.65\n",
      "beatings- Recall for LogisticRegression(max_iter=1000) model, train set: 0.06531881804043546\n",
      "beatings- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.08125\n",
      "LogisticRegression(max_iter=1000)\n",
      "crowddispersal- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.657023000144655\n",
      "crowddispersal- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.6085946573751453\n",
      "crowddispersal- Precision for LogisticRegression(max_iter=1000) model, train set: 0.7373376623376623\n",
      "crowddispersal- Precision for LogisticRegression(max_iter=1000) model, test set: 0.6649746192893401\n",
      "crowddispersal- Recall for LogisticRegression(max_iter=1000) model, train set: 0.5924863031567963\n",
      "crowddispersal- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.5610278372591007\n",
      "LogisticRegression(max_iter=1000)\n",
      "ignore- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.794378288562725\n",
      "ignore- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.7804335742078933\n",
      "ignore- Precision for LogisticRegression(max_iter=1000) model, train set: 0.7336317135549872\n",
      "ignore- Precision for LogisticRegression(max_iter=1000) model, test set: 0.7225939269171384\n",
      "ignore- Recall for LogisticRegression(max_iter=1000) model, train set: 0.8660929951690821\n",
      "ignore- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.8483383685800604\n",
      "LogisticRegression(max_iter=1000)\n",
      "killings- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.17120622568093383\n",
      "killings- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.12435233160621761\n",
      "killings- Precision for LogisticRegression(max_iter=1000) model, train set: 0.5789473684210527\n",
      "killings- Precision for LogisticRegression(max_iter=1000) model, test set: 0.48\n",
      "killings- Recall for LogisticRegression(max_iter=1000) model, train set: 0.1004566210045662\n",
      "killings- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.07142857142857142\n",
      "LogisticRegression(max_iter=1000)\n",
      "shootings- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.21176470588235294\n",
      "shootings- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.1722488038277512\n",
      "shootings- Precision for LogisticRegression(max_iter=1000) model, train set: 0.5689655172413793\n",
      "shootings- Precision for LogisticRegression(max_iter=1000) model, test set: 0.4864864864864865\n",
      "shootings- Recall for LogisticRegression(max_iter=1000) model, train set: 0.13009198423127463\n",
      "shootings- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.10465116279069768\n",
      "LogisticRegression(max_iter=1000)\n",
      "{'target': ['arrests', 'accomodation', 'beatings', 'crowddispersal', 'ignore', 'killings', 'shootings'], 'f1_score_train': [0.1408450704225352, 0.03843074459567654, 0.11881188118811882, 0.657023000144655, 0.794378288562725, 0.17120622568093383, 0.21176470588235294], 'f1_score_test': [0.1310211946050096, 0.053571428571428575, 0.14444444444444446, 0.6085946573751453, 0.7804335742078933, 0.12435233160621761, 0.1722488038277512], 'precision_train': [0.5895196506550219, 0.5454545454545454, 0.65625, 0.7373376623376623, 0.7336317135549872, 0.5789473684210527, 0.5689655172413793], 'precision_test': [0.5666666666666667, 0.6, 0.65, 0.6649746192893401, 0.7225939269171384, 0.48, 0.4864864864864865], 'recall_train': [0.07997630331753554, 0.01991701244813278, 0.06531881804043546, 0.5924863031567963, 0.8660929951690821, 0.1004566210045662, 0.13009198423127463], 'recall_test': [0.07407407407407407, 0.028037383177570093, 0.08125, 0.5610278372591007, 0.8483383685800604, 0.07142857142857142, 0.10465116279069768]}\n"
     ]
    }
   ],
   "source": [
    "model_performance_dict = {\n",
    "    'target':[],\n",
    "#     'model':[],\n",
    "    'f1_score_train':[],\n",
    "    'f1_score_test':[],\n",
    "    'precision_train':[],\n",
    "    'precision_test':[],\n",
    "    'recall_train':[],\n",
    "    'recall_test':[] \n",
    "}\n",
    "\n",
    "# ['arrests','accomodation','beatings','crowddispersal','ignore','killings','shootings']\n",
    "# ['arrests_BC', 'accomodation_BC', 'beatings_BC', 'crowddispersal_BC', 'ignore_BC', 'killings_BC', 'shootings_BC']\n",
    " \n",
    "targets = ['arrests','accomodation','beatings','crowddispersal','ignore','killings','shootings']    \n",
    "    \n",
    "for target in targets:\n",
    "    \n",
    "    predicted_column, probability_column, f1_score_train, f1_score_test, precision_train, precision_test, recall_train, recall_test = state_response_predictor(\n",
    "                                                                                                                                mass, \n",
    "                                                                                                                                features_1, \n",
    "                                                                                                                                target, \n",
    "                                                                                                                                LogisticRegression_1)\n",
    "    \n",
    "    model_performance_dict['target'].append(target)\n",
    "#     model_performance_dict['class_balance'].append(mass[classifier].value_counts(normalize=True))\n",
    "#     model_performance_dict['model'].append(model)\n",
    "    model_performance_dict['f1_score_train'].append(f1_score_train)\n",
    "    model_performance_dict['f1_score_test'].append(f1_score_test)\n",
    "    model_performance_dict['precision_train'].append(precision_train)\n",
    "    model_performance_dict['precision_test'].append(precision_test)\n",
    "    model_performance_dict['recall_train'].append(recall_train)\n",
    "    model_performance_dict['recall_test'].append(recall_test)\n",
    "    \n",
    "print(model_performance_dict)\n",
    "    \n",
    "# model_performance_df = pd.DataFrame(model_performance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>recall_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arrests</td>\n",
       "      <td>0.140845</td>\n",
       "      <td>0.131021</td>\n",
       "      <td>0.589520</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.079976</td>\n",
       "      <td>0.074074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accomodation</td>\n",
       "      <td>0.038431</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.019917</td>\n",
       "      <td>0.028037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beatings</td>\n",
       "      <td>0.118812</td>\n",
       "      <td>0.144444</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.065319</td>\n",
       "      <td>0.081250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crowddispersal</td>\n",
       "      <td>0.657023</td>\n",
       "      <td>0.608595</td>\n",
       "      <td>0.737338</td>\n",
       "      <td>0.664975</td>\n",
       "      <td>0.592486</td>\n",
       "      <td>0.561028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ignore</td>\n",
       "      <td>0.794378</td>\n",
       "      <td>0.780434</td>\n",
       "      <td>0.733632</td>\n",
       "      <td>0.722594</td>\n",
       "      <td>0.866093</td>\n",
       "      <td>0.848338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>killings</td>\n",
       "      <td>0.171206</td>\n",
       "      <td>0.124352</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.100457</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>shootings</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.172249</td>\n",
       "      <td>0.568966</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.130092</td>\n",
       "      <td>0.104651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           target  f1_score_train  f1_score_test  precision_train  \\\n",
       "0         arrests        0.140845       0.131021         0.589520   \n",
       "1    accomodation        0.038431       0.053571         0.545455   \n",
       "2        beatings        0.118812       0.144444         0.656250   \n",
       "3  crowddispersal        0.657023       0.608595         0.737338   \n",
       "4          ignore        0.794378       0.780434         0.733632   \n",
       "5        killings        0.171206       0.124352         0.578947   \n",
       "6       shootings        0.211765       0.172249         0.568966   \n",
       "\n",
       "   precision_test  recall_train  recall_test  \n",
       "0        0.566667      0.079976     0.074074  \n",
       "1        0.600000      0.019917     0.028037  \n",
       "2        0.650000      0.065319     0.081250  \n",
       "3        0.664975      0.592486     0.561028  \n",
       "4        0.722594      0.866093     0.848338  \n",
       "5        0.480000      0.100457     0.071429  \n",
       "6        0.486486      0.130092     0.104651  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance_df = pd.DataFrame(model_performance_dict)\n",
    "model_performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arrests- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.2027871215761653\n",
      "arrests- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.18148820326678766\n",
      "arrests- Precision for LogisticRegression(max_iter=1000) model, train set: 0.5368956743002544\n",
      "arrests- Precision for LogisticRegression(max_iter=1000) model, test set: 0.5434782608695652\n",
      "arrests- Recall for LogisticRegression(max_iter=1000) model, train set: 0.125\n",
      "arrests- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.10893246187363835\n",
      "LogisticRegression(max_iter=1000)\n",
      "accomodation- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.03522818254603683\n",
      "accomodation- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.041666666666666664\n",
      "accomodation- Precision for LogisticRegression(max_iter=1000) model, train set: 0.5\n",
      "accomodation- Precision for LogisticRegression(max_iter=1000) model, test set: 0.4666666666666667\n",
      "accomodation- Recall for LogisticRegression(max_iter=1000) model, train set: 0.018257261410788383\n",
      "accomodation- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.021806853582554516\n",
      "LogisticRegression(max_iter=1000)\n",
      "beatings- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.11830985915492959\n",
      "beatings- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.15469613259668508\n",
      "beatings- Precision for LogisticRegression(max_iter=1000) model, train set: 0.6268656716417911\n",
      "beatings- Precision for LogisticRegression(max_iter=1000) model, test set: 0.6666666666666666\n",
      "beatings- Recall for LogisticRegression(max_iter=1000) model, train set: 0.06531881804043546\n",
      "beatings- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.0875\n",
      "LogisticRegression(max_iter=1000)\n",
      "crowddispersal- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.6536118363794603\n",
      "crowddispersal- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.6089482858803023\n",
      "crowddispersal- Precision for LogisticRegression(max_iter=1000) model, train set: 0.7360339758248938\n",
      "crowddispersal- Precision for LogisticRegression(max_iter=1000) model, test set: 0.6658195679796697\n",
      "crowddispersal- Recall for LogisticRegression(max_iter=1000) model, train set: 0.5877902426297938\n",
      "crowddispersal- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.5610278372591007\n",
      "LogisticRegression(max_iter=1000)\n",
      "ignore- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.7930507296733843\n",
      "ignore- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.7781493868450391\n",
      "ignore- Precision for LogisticRegression(max_iter=1000) model, train set: 0.7347411795003863\n",
      "ignore- Precision for LogisticRegression(max_iter=1000) model, test set: 0.7221934816347646\n",
      "ignore- Recall for LogisticRegression(max_iter=1000) model, train set: 0.8614130434782609\n",
      "ignore- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.8435045317220544\n",
      "LogisticRegression(max_iter=1000)\n",
      "killings- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.1703225806451613\n",
      "killings- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.13541666666666666\n",
      "killings- Precision for LogisticRegression(max_iter=1000) model, train set: 0.559322033898305\n",
      "killings- Precision for LogisticRegression(max_iter=1000) model, test set: 0.5416666666666666\n",
      "killings- Recall for LogisticRegression(max_iter=1000) model, train set: 0.1004566210045662\n",
      "killings- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.07738095238095238\n",
      "LogisticRegression(max_iter=1000)\n",
      "shootings- F1_score for LogisticRegression(max_iter=1000) model, train set: 0.21864951768488747\n",
      "shootings- F1_score for LogisticRegression(max_iter=1000) model, test set: 0.16346153846153846\n",
      "shootings- Precision for LogisticRegression(max_iter=1000) model, train set: 0.5930232558139535\n",
      "shootings- Precision for LogisticRegression(max_iter=1000) model, test set: 0.4722222222222222\n",
      "shootings- Recall for LogisticRegression(max_iter=1000) model, train set: 0.1340341655716163\n",
      "shootings- Recall for LogisticRegression(max_iter=1000) model, teset set: 0.09883720930232558\n",
      "LogisticRegression(max_iter=1000)\n",
      "{'Classifier': 'shootings', 'model': LogisticRegression(max_iter=1000), 'f1_score_train': 0.21864951768488747, 'f1_score_test': 0.16346153846153846, 'precision_train': 0.5930232558139535, 'precision_test': 0.4722222222222222, 'recall_train': 0.1340341655716163, 'recall_test': 0.09883720930232558}\n"
     ]
    }
   ],
   "source": [
    "model_performance_dict = {}\n",
    " \n",
    "for classifier in ['arrests','accomodation','beatings','crowddispersal','ignore','killings','shootings']:\n",
    "    \n",
    "    predicted_column, probability_column, f1_score_train, f1_score_test, precision_train, precision_test, recall_train, recall_test = state_response_predictor(\n",
    "                                                                                                                                mass, \n",
    "                                                                                                                                features_1, \n",
    "                                                                                                                                classifier, \n",
    "                                                                                                                                LogisticRegression_1)\n",
    "     \n",
    "    model_performance_dict['Classifier'].append(classifier)\n",
    "#     model_performance_dict['class_balance'] = mass[classifier].value_counts(normalize=True))\n",
    "    model_performance_dict['model'] = model\n",
    "    model_performance_dict['f1_score_train'].append(f1_score_train)\n",
    "    model_performance_dict['f1_score_test'].append(f1_score_test)\n",
    "    \n",
    "    model_performance_dict['precision_train'] = precision_train\n",
    "    model_performance_dict['precision_test'] = precision_test\n",
    "    model_performance_dict['recall_train'] = recall_train\n",
    "    model_performance_dict['recall_test'] = recall_test\n",
    "    \n",
    "print(model_performance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-c27f4c62a9c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_performance_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_performance_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_performance_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         ]\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraw_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"If using all scalar values, you must pass an index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhave_series\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "model_performance_df = pd.DataFrame(model_performance_dict)\n",
    "model_performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.858982\n",
       "1    0.141018\n",
       "Name: arrests, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass['arrests'].value_counts(normalize=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.543777\n",
       "0    0.456223\n",
       "Name: ignore, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass['ignore'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.947258\n",
       "1    0.052742\n",
       "Name: beatings, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass['beatings'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.938719\n",
       "1    0.061281\n",
       "Name: shootings, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass['shootings'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.945813\n",
       "1    0.054187\n",
       "Name: killings, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass['killings'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.89977\n",
       "1    0.10023\n",
       "Name: accomodation, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass['accomodation'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.686897\n",
       "1    0.313103\n",
       "Name: crowddispersal, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass['crowddispersal'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logreg_cvec_pipe = Pipeline([\n",
    "#         ('cvec', CountVectorizer(stop_words=all_stop_words)),\n",
    "#         ('logreg', LogisticRegression())\n",
    "#     ])\n",
    "\n",
    "# logreg = LogisticRegression()\n",
    "\n",
    "# params = {\n",
    "#     'C': [0.01, 0.1, 1, 10, 100],\n",
    "#     'penalty' : ['l1', 'l2'],\n",
    "#     'solver': ['lbfgs', 'saga']\n",
    "# }\n",
    "\n",
    "# log_reg_grid = GridSearchCV(logreg, \n",
    "#                    params,\n",
    "#                    cv = 5,\n",
    "#                    verbose = 2,\n",
    "#                    n_jobs=2)\n",
    "\n",
    "# logreg_cvec_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
